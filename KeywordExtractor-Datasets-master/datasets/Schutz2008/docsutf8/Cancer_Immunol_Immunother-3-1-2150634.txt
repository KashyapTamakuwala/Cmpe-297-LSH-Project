Cancer Immunol Immunother
Cancer Immunology, Immunotherapy 
0340-7004
1432-0851
Springer-Verlag
Berlin/Heidelberg


2150634
17721781
380
10.1007/s00262-007-0380-6
Original Article


Results and harmonization guidelines from two large-scale international Elispot proficiency panels conducted by the Cancer Vaccine Consortium (CVC/SVI)

Janetzki
Sylvia

+1-201-3460710
+1-201-3460715
sylvia@zellnet.com

1
2

Panageas
Katherine S.

3

Ben-Porat
Leah

3

Boyer
Jean

4

Britten
Cedrik M.

5

Clay
Timothy M.

6

Kalos
Michael

7

Maecker
Holden T.

8

Romero
Pedro

9

Yuan
Jianda

10

Martin Kast
W.

11

Hoos
Axel

12

for the Elispot Proficiency Panel of the CVC Immune Assay Working Group

1
555 North Avenue, Suite 25-S, Fort Lee, NJ 07024 USA 
2
ZellNet Consulting, Inc, Fort Lee, NJ USA 
3
Department of Epidemiology and Biostatistics, Memorial Sloan-Kettering Cancer Center, New York, NY USA 
4
Department of Pathology and Laboratory Medicine, University of Pennsylvania, Philadelphia, PA USA 
5
Department for Blood Transfusion and Immunhematology, Leiden University Medical Centre, Leiden, The Netherlands 
6
Department of Surgery and Duke Comprehensive Cancer Center, Duke University Medical Center, Durham, NC USA 
7
Clinical Immunobiology Correlative Studies Laboratory, Division of Cancer Immunotherapeutics and Tumor Immunology, Division of Hematology and Hematopoietic Cell Transplantation, City of Hope National Medical Center, Duarte, CA USA 
8
BD Biosciences, San Jose, CA USA 
9
Division of Clinical Onco-Immunology, Ludwig Institute for Cancer Research, Lausanne Branch, University Hospital (CHUV), Lausanne, Switzerland 
10
Department of Medicine, Memorial Sloan-Kettering Cancer Center, New York, NY USA 
11
Department of Molecular Microbiology and Immunology, Norris Comprehensive Cancer Center, University of Southern California, Los Angeles, CA USA 
12
Bristol-Myers Squibb, Wallingford, CT USA 

25
8
2007

3
2008

57
3
303
315
23
4
2007

17
7
2007


© Springer-Verlag 2007

The Cancer Vaccine Consortium of the Sabin Vaccine Institute (CVC/SVI) is conducting an ongoing large-scale immune monitoring harmonization program through its members and affiliated associations. This effort was brought to life as an external validation program by conducting an international Elispot proficiency panel with 36 laboratories in 2005, and was followed by a second panel with 29 participating laboratories in 2006 allowing for application of learnings from the first panel. Critical protocol choices, as well as standardization and validation practices among laboratories were assessed through detailed surveys. Although panel participants had to follow general guidelines in order to allow comparison of results, each laboratory was able to use its own protocols, materials and reagents. The second panel recorded an overall significantly improved performance, as measured by the ability to detect all predefined responses correctly. Protocol choices and laboratory practices, which can have a dramatic effect on the overall assay outcome, were identified and lead to the following recommendations: (A) Establish a laboratory SOP for Elispot testing procedures including (A1) a counting method for apoptotic cells for determining adequate cell dilution for plating, and (A2) overnight rest of cells prior to plating and incubation, (B) Use only pre-tested serum optimized for low background: high signal ratio, (C) Establish a laboratory SOP for plate reading including (C1) human auditing during the reading process and (C2) adequate adjustments for technical artifacts, and (D) Only allow trained personnel, which is certified per laboratory SOPs to conduct assays. Recommendations described under (A) were found to make a statistically significant difference in assay performance, while the remaining recommendations are based on practical experiences confirmed by the panel results, which could not be statistically tested. These results provide initial harmonization guidelines to optimize Elispot assay performance to the immunotherapy community. Further optimization is in process with ongoing panels.

Keywords
Elispot
Proficiency panel
Validation
Harmonization
Immune monitoring

issue-copyright-statement
© Springer-Verlag 2008




Introduction
6
17
25
39
11
22
24
26
38
]. Despite the overwhelming use of various immune assays for exactly that purpose, reported results are often met with skepticism, caused mainly by two reasons: (1) high variability among results from the same laboratories and/or among different laboratories, and (2) the lack of demand to report standardization, validation and training strategies as well as assay acceptance criteria by the laboratories conducting immune testing. This is surprising since the reporting of results for other clinical endpoints, e.g., side effects, has to follow strict guidelines and definitions.
28
27
To provide regulatory and sponsoring agencies with confidence that reported data are generated following necessary standards and rigor that supports product licensure.

To provide an external validation tool for individual labs.

3
].


5
32
33
2
33
32
5
25
31
].
In contrast, immune monitoring approaches in the cancer vaccine field are more heterogeneous, based on the vast variety of vaccine design, type of cancer, and availability of antigen presenting cells. Standardization of the entire Elispot protocol across laboratories is therefore not feasible. We set out to devise a strategy to identify issues and deficiencies in current Elispot practices, and to identify common sources of assay variability within and between laboratories, with the extended goal of standardizing the identified factors in an assay harmonization effort across laboratories.
In 2005, the Cancer CVC/SVI initiated an Elispot proficiency panel program to achieve this goal. In addition to offering an external validation program, the CVC addressed the need for such strategy by comparing assay performance across the field, identifying critical protocol choices and gaining an overview of training and validation practices among participating laboratories.
For this program, predefined PBMCs from four donors with different ranges of reactivity against two peptide pools were sent to participants for Elispot testing. Laboratories had to further provide cell recovery and viability data, as well as respond to surveys describing their protocol choices and training and validation status.
In response to the survey results, the CVC/SVI established requirements for laboratories to participate in future proficiency panels, which included the existence of a Standard Operating Procedure (SOP) prior to joining the program. Further, individualized assay performance assessment was offered to all laboratories, together with suggestions for implementation of protocol optimization steps.
1
Fig. 1
Initial guidelines for harmonization of the Elispot assay to optimize assay performance and reproducibility derived from two international proficiency panels, based on their findings and trends observed





Materials and methods
Participants and organizational setup
All participants were members of the Cancer Vaccine Consortium or its affiliated institutions, the Ludwig Institute for Cancer Research (LICR) and the Association for Immunotherapy of Cancer (C-IMT). Laboratories were located in ten countries (Australia, Belgium, Canada, Germany, Italy, Japan, France, Switzerland, UK, and USA). Each laboratory received an individual lab ID number. Panel leadership was provided by a scientific leader experienced in Elispot, in collaboration with the CVC Executive office. SeraCare BioServices, Gaithersburg, MD, served as central laboratory, providing cells, pretesting and shipping services, as well as logistical services like blinding of panelists. IDs were not revealed to panel leader, CVC or statistician during the panel.
Thirty-six laboratories including the central lab participated in panel 1, 29 including the central lab in panel 2. Twenty-three laboratories participated in both panels. Six new panelists were added to the second testing round. Thirteen dropped out after the first panel. Main reasons for drop out were switch of assay priorities and not meeting criteria for panel participation. Various groups stated that one time participation fulfilled their need for external validation.

PBMCs and peptides
20
] in which the following was validated: cell separation procedure, freezing media, dispensing effect on function, freezing procedure, and shipping on dry ice. It was demonstrated that functionality and viability were maintained throughout the procedure. In addition, Elispot values from fresh and frozen PBMCs, shipped on dry ice, were nearly equivalent.
Each vial of PBMCs contained enough cells to ensure a recovery of 10 million cells or more under Seracare’s SOP.
7
23
7
23
]. PBMCs were selected for no, low, medium and strong responses against both peptide pools, and repeatedly Elispot-tested at Seracare in order to confirm responder status. Response definition was set arbitrarily for the spot number/well (200,000 PBMC): no responder: average median/panel 1 + 2 = 1 (CMV and CEF); low responder: average median/panel 1 + 2 = 18 (CMV) and 40 (CEF); medium responder: average median/panel 1 + 2 = 98 (CMV) and 127 (CEF); and high responder: average median/panel 1 + 2 = 396 (CMV) and 398 (CEF).
Peptide pools were resuspended in DMSO and further diluted with PBS to a final concentration of 20 μg/ml. Aliquots of 150 μl of peptide pool were prepared for final shipment to participants. Corresponding PBS/DMSO aliquots for medium controls were also prepared. Participants were blinded to the content of these vials, which were labeled as “Reagent 1, 2 or 3”.
All cells and reagents sent to participants in both panels were obtained from the same batches.
Cells and reagent vials were shipped to all participants for overnight delivery on sufficient dry ice for 48 h. Shipping was performed by Seracare under their existing SOPs.

Elispot
Participants received a plate layout template and instructions for a direct IFNγ Elispot assay which had to be performed in one Elispot plate. Each donor was tested in six replicates against three reagents (medium, CEF and CMV peptide pool). Further, 24 wells were tested for the occurrence of false positive spots by the addition of T cell medium only. About 200,000 PBMC/well were tested against 1 μg/ml peptide pool or the equivalent amount of PBS/DMSO. All other protocol choices were left to the participants, including choices about: Elispot plate, antibodies, spot development, use of DNAse, resting of cells, T cell serum, cell counting and spot counting method. All plates were reevaluated at ZellNet Consulting (Fort Lee, NJ) with a KS Elispot system (Carl Zeiss, Thornwood, NY), software KS Elispot 4.7 (panel 1) and KS Elispot 4.9 (panel 2) in blinded fashion. Each well in each plate was audited.
5
5
8
].

Statistical analysis
t 
test was applied.


Results
Feasibility
In the first proficiency panel, shipping and Elispot testing among 36 laboratories from 9 countries were conducted without delays. The success of this panel demonstrates the feasibility of such large international studies, the biggest of such format as of today, under the described organizational setup. The second panel with 29 participating laboratories from 6 countries followed the approach of panel 1. However, customs delays of dry ice shipments to some international sites required repeated shipments of cells and antigens to these destinations. Based on this experience, the use of dryshippers with liquid nitrogen is being implemented for international destinations in the third CVC panel round in 2007.

Recovery and viability of PBMCs in panel 1 and 2
1
Table 1
Cell recovery and viability in both proficiency panels


a

b

Median P1/P2
Minimum P1/P2
Maximum P1/P2


6
 cells
1
12.5/11.5
12.0/12.0
6.8/1.0
26.4/18.8

2
13.3/12.3
13.2/12.6
5.5/0.3
28.4/22.4

3
13.1/12.8
13.6/12.8
6.7/1.7
25.1/24.3

4
12.8/12.4
11.9/12.9
5.6/6.2
34.4/22.7

Viability (%)
1
88/85
89/89
48/58
100/98

2
87/88
89/90
57/67
100/98

3
91/87
93/90
54/69
100/100

4
86/89
90/92
43/75
100/98



a
PBMCs from same donors and batches were used in both panels
b
P1/P2 refer to data from panel 1 (P1) and panel 2 (P2)



Interestingly, only 4/10 laboratories in panel 1, and 4/7 laboratories in panel 2 with recoveries below 8 million cells were from international locations. Similar, only 1/5 laboratories in panel 1 and 2/5 in panel 2 reporting viabilities less than 70% belonged to international sites. This clearly demonstrates that location for dry ice shipment had no effect on overall cell recovery and viability.
We also investigated whether low (<8 million) or very high (>20 million) cell recovery had an influence on spot counts, assuming that these were potential erroneous cell counts, leading to too low or too high cell dilutions, respectively, what in turn would lead to too high (in case of underestimating cell number) or too low (in case of overestimating cell number) spots counts. However, except for a few sporadic incidents, there was no correlation between cell counts and spot counts (data not shown) in either direction. Only one laboratory with low recovery and low viability was found to have peptide pool-specific spot counts for all donors much below the panel median.
P
5
).

Elispot results in panel 1
All 36 laboratories completed testing of all 4 donors against medium, CEF and CMV peptide pool. Spot appearance and size as well as occurrence of artifacts differed dramatically among laboratories (not shown). Four outlier laboratories were identified, which detected less than half of the responses correctly. In all four cases, detected responses were well below the panel median, and often, there was high background reactivity (up to 270 spots/well) in medium controls. No obvious protocol choices could be identified which could have been responsible for the suboptimal performance. One out of the four laboratories had little experience at the date of the panel. Another group reported a less experienced scientist performing the assay. A third outlier repeated the assay, and was able to perform adequately. No feed back was available from the fourth group.
2
Fig. 2
Panel 1 
panel 2 
box plots 
box 
triangle 
horizontal line 
upper 
lower mark
horizontal line 
across a graph demonstrates the overall panel median. The central laboratory performed the assay under two different conditions in panel 1. Results from both experiments are presented; therefore 37 laboratories for panel 1. Laboratory ID numbers do not correlate in both panels. In panel 1, laboratory #18 reported spot counts for the medium control as high as 270 per well (mean 81, median 34.5). For proper illustration of all other panel data, these data were omitted from the graph. Intra-laboratory variability and variability among participants as well as reactivity against medium are representative for all responder PBMCs tested




3
Fig. 3
Lab X
Y
Z
). Respective well images are shown below each column for that specific group. Differences in lab-specific spot counts (“own”) and counts from reevaluation in an independent laboratory (“central”) including resulting variability measures are presented in the table




A similar scenario was found for response detection against the CEF peptide pool. Thirteen laboratories missed to detect the response, one of which due to high reactivity against medium, and one due to inaccurate spot counting.
An interesting observation was that 23 groups reported false positive spots in a range of 1–26 spots/well. Reevaluation revealed that the actual number of groups with false positive spots was lower (12), and the false positive spot number range per well fell between 0 and 8.

Survey results about protocol
During the first panel, participants had to provide information about their protocol choices: plates, potential prewetting of PVDF, antibodies, enzyme, substrate, use of DNAse during PBMC thawing, resting of cells, serum used, cell counting, and plate reader. There was a wide range of protocol choices across the panel participants. The most common choices for the parameters listed above were as follows: use of PVDF plates (64%) prewetted with Ethanol (52%), coated with Mabtech antibodies (67%) at 0.5–0.75 μg/well (33%); spot development with HRP (53%) from Vector Laboratories (33%) using AEC (44%) from Sigma (42%); no use of DNAse when thawing cells (83%), and no resting period for cells prior to the assay (53%); use of human serum (64%); cell counting with trypan blue exclusion using a hemocytometer (78%); and plate evaluation with a Zeiss reader (36%).
There were some clear trends for international sites with preferred use of the AP/BCIP/NBT development system (83 via 29% in the US), the use of nitrocellulose plates (75 via 21% in the US), and the use of Mabtech antibodies (83 via 58% in the US). On the other hand, 7/8 laboratories using an automated cell counter were located in the US.
4
Fig. 4
a
b
box plots 
box 
triangle 
horizontal line 
upper 
lower mark
triangle 
a
b
. The table contains reference to the figure above, and information about specific protocol choices




5
Fig. 5
a
b
D1–4 
med 
medium). The mean viability per donor reported by Guava users and users of other cell counting methods (one lab used an automated cell counter from Beckman Coulter, all others used a hemocytometer with trypan blue exclusion) is presented in the table below the figure




6
P
P
Fig. 6
P
P
t 
test)





Survey results about validation and training practices
During the lively discussion of the results of panel 1 and its protocol survey at the Annual CVC meeting in Alexandria in November 2005, it was suggested that the level of experience, standardization and validation of participating laboratories might have been the cause for the variability and performances observed. In response, we conducted a survey among panelists, in which 30 laboratories participated. As expected, the experience and Elispot usage varied significantly. Some laboratories had the Elispot assay established less than one year before panel testing, whereas others used the assay for more than 10 years. The experience of the actual performer of the panel assay also varied widely.
Interestingly, even though 2/3 of participants reported to have specific training guidelines for new Elispot performers in place, more than 50% never or rarely checked on the scientist’s performance after the initial training.
Almost all laboratories indicated that they use an SOP that had been at least partially qualified and/or validated. Validation tools and strategies varied widely. Only 12 groups monitored variability, whereas 23 reported the use of external controls of some kind (e.g., T cell lines, predefined PBMC, parallel tetramer testing).
Thirteen groups were found to have some kind of criteria implemented for assay acceptance. Among the 20 different criteria reported, not one was described by more than one lab.
Mirroring these survey results, 20 laboratories believed that they need to implement more validation steps. All except one group expressed their strong interest in published guidelines for validation and training strategies for Elispot.

Elispot results in panel 2
P
2
). The overall panel median for the CMV-response in the weak responder increased from 14 spots in panel 1 to 21 spots in panel 2, and for the CEF response from 30 to 51, respectively.
Of the 23 labs repeating the panel, 8 had changed their protocol before panel 2, 3 of which as an immediate response to results from the first panel. One outlier lab from panel 1 participated in panel 2, and improved its performance by detecting all responses correctly as per reevaluation counts. Only their lab-specific evaluation did not detect the low CMV responder. Overall, 4/23 panel-repeating labs (17%) did not detect the low CMV-responder, 3 of which also did not detect this response in panel 1. About 10/23 groups missed the low CMV responder in panel 1, but 7 of these laboratories were able to detect it in panel 2. Only one repeater detected the low CMV response in panel 1, but not panel 2. This is a clear performance improvement for that group (47% missed this response in panel 1), and highlights the usefulness of multiple participation in panel testing as an external training program.
We ran an in-depth analysis of the results and previous survey responses, where available, from participants who missed the weak responder, as well as from laboratories with marginal detection of response, including personal communication. We were able to narrow down the possible sources for these performances. Two laboratories missed responses due to inaccurate evaluation, during which they either included artifacts into spot counts or simply did not count the majority of true spots, as central reevaluation revealed. One laboratory did not follow the assay guidelines. The majority of laboratories, however, followed common protocol choices, but had either very low response detection across all donors and antigens, or detected very high background reactivity in some or all donors. This pattern pointed to serum as the possible cause for suppressed reactivity or non-specific stimulation. Three of these laboratories shared with the CVC that retesting their serum choice indicated that they had worked with a suboptimal serum during the panel; and that they now successfully introduced a different serum/medium to their protocol with improved spot counts. Serum choices included human AB serum, FCS, FBS, and various serum-free media. There was no difference in assay performance detectable between these groups.


Discussion
2
14
4
). This observation supports the premise that many common Elispot materials and reagents (e.g., plates, antibodies, spot development reagents) perform equally or similarly well; and that there are other factors which influence the outcome of the Elispot assay.
3
5
15
]. Despite the availability of high resolution readers and software features for automated spot gating and other potentially helpful options, it is essential to employ well trained operators for spot counting, to audit all plates, and to implement changes of reading parameter in cases when well and spot appearances differ from the overall assay, typically for technical reasons. For that, SOPs used for plate evaluation might require revision. The use of available certification and training services can be helpful.
4
21
35
] recently reported the usefulness of apoptosis acceptance criteria that allowed the separation of PBMC samples by their ability to respond to an antigenic stimulus or not.
16
18
6
2
]. Even though almost half of participants in panel 1 let cells rest before addition to the plate, there was no clear correlation to the magnitude of peptide-specific spot counts. This might have been due to the variation of resting times between 0.5 and 20 h, and other protocol variables, which included the actual resting protocol. Factors like serum and serum concentration, cell concentration, and actual storage condition (e.g., tissue culture flasks or plates can lead to cell adherence and therefore loss of professional antigen-presenting cells) are known to influence the success of cell resting.
16
]. It is critical to choose serum that supports low background reactivity, but strong signals. The leading choice in this panel to use human AB serum reflects the historic preference for human immune assays. Each serum batch, however, is unique in its ability to support optimal assay resolution, and may potentially contain mitogenic or immune suppressive factors. There was some anecdotal evidence that the serum choice among our panelists was responsible for suboptimal performance. Interestingly, six laboratories preferred to work with serum-free medium. None of these groups observed high background reactivity, but two failed to detect the weak responder.
P
 < 0.01). This improvement might have been partially due to the stricter participant selection in panel 2. However, 7/10 labs repeating the panel improved their performance by correctly detecting the low CMV responder in panel 2, while missed in panel 1. A striking finding was that 2/3 of all laboratories stated that they believed they needed to implement more validation. And all but one group expressed their wish for published guidelines for Elispot assay validation and training.
Initial Elispot Harmonization Guidelines for Optimizing Assay Performance 
1
Cancer Vaccine Clinical Trial Working Group 
12
]. Further optimization is aimed for through ongoing proficiency panel work conducted by the CVC.
30
1
19
25
34
9
13
37
10
16
29
36
]. And even these few publications give only limited advice on how to validate the Elispot assay in a given laboratory setting, not to mention specific training guidelines.
Furthermore, acceptance criteria for assay performance were only used by a limited number of laboratories, and each criterion was unique for the laboratory that used it.
These observations should be a wake-up call for the immune monitoring community, which does not only include the cancer vaccine field, but also the infectious disease and autoimmunity field and others. General assay practices for the detection of antigen-specific T cells are comparable across all fields. The CVC as part of the Sabin Vaccine Institute is intending to develop and tighten collaborations with groups from other research and vaccine development areas. Published documents with specific criteria for Elispot assay validation, assay acceptance criteria and training guidelines will be most valuable for the immune monitoring field, and are now being established as CVC guidelines as a result of the described studies. Continuous external validation programs need to be a part of these efforts in order to check upon the success of inter-laboratory harmonization including assay optimization, standardization and validation as well as of laboratory-specific implementation of guidelines and protocol recommendations. These efforts are essential to establish the Elispot assay and other immune assays as standard monitoring tools for clinical trials.


Special thanks to C. Wrotnowski for his work in initializing the proficiency panel program of the CVC. W. M. Kast is the holder of the Walter A. Richter Cancer Research Chair and is supported by the Beckman Center for Immune Monitoring.

Appendix: CVC Elispot proficiency panel members (in alphabetical order)
Richard Anderson, Oxxon Therapeutics Ltd, Oxford, UK

Nadege Bercovici, IDM S.A., Paris, France

Jean Boyer, University of Pennsylvania, Philadelphia, PA

Cedrik Britten, Johann-Gutenberg University Mainz, Germany

Dirk Brockstedt, Cerus Corporation, Concord, CA

Judy Caterini, sanofi pasteur, Toronto, Canada

Vincenco Cerundolo, Ludwig Institute for Cancer Research, Weatherall Institute of Molecular Medicine, Oxford, UK

Weisan Chen, Ludwig Institute for Cancer Research, Heidelberg, Australia

Timothy Clay, Duke University Medical Center, Durham, NC

Robert Darnell, Rockefeller University, New York, NY

Sheri Dubey, Merck & Co, Inc., West Point, PA

Thomas Ermak, Acambis, Cambridge, MA

Sacha Gnjatic, Ludwig Institute for Cancer Research, Memorial Sloan-Kettering Cancer Center, New York, NY

Richard Harrop, Oxford BioMedica, Oxford, UK

Don Healey, Argos Therapeutics, Inc., Durham, NC

Alan Houghton, Memorial Sloan-Kettering Cancer Center, New York, NY

Elke Jaeger, Ludwig Institute for Cancer Research, Krankenhaus Nordwest, Frankfurt, Germany

William Janssen, H Lee Moffitt Cancer Center, University of South Florida, Tampa, FL

Lori Jones, Dendreon Corporation, Seattle, WA

W. Martin Kast, Norris Comprehensive Cancer Center, USC, Los Angeles CA

Julia Kaufman, Rockefeller University, New York, NY

Alexander Knuth, Ludwig Institute for Cancer Research, University Hospital Zürich, Zürich, Switzerland

Abdo Konur, Johann-Gutenberg University Mainz, Germany

Ferdynand Kos, Johns Hopkins University School of Medicine, Baltimore, MD

Odunsi Kunle, Ludwig Institute for Cancer Research, Roswell Park Cancer Institute, Buffalo, NY

Kelledy Manson, Therion Biologics Corporation, Cambridge, MA

Mark Matijevic, MGI Pharma Biologicals, Lexington, MA

Yoshishiro Miyahara, Ludwig Institute for Cancer Research, Mie University Graduate School of Medicine, Mie, Japan

Cristina Musselli, Antigenics, Inc., Lexington, MA

Walter Olson, University of Virginia Health System, Charlottesville, VA

Dennis Panicali, Therion Biologics Corporation, Cambridge, MA

Shreemanta Parida, Max-Planck Institute for Infection Biology, Berlin, Germany

Joanne Parker, Globeimmune Inc., Louisville, CO

Heike Pohla, Ludwig-Maximilians University, München, Germany

Michael Pride, Wyeth Pharmaceuticals, Pearl River, NY

Ruth Rappaport, Wyeth Pharmaceuticals, Pearl River, NY

Philip Reay, Biovex, Abingdon, UK

Licia Rivoltini, Istituto Nazionale Tumori, Milano, Italy

Pedro Romero, Ludwig Institute for Cancer Research, Hospital Orthopedique, Lausanne, Switzerland

Patric Schiltz, Hoag Cancer Center, Newport Beach, CA

Hiroshi Shiku, Ludwig Institute for Cancer Research, Mie University Graduate School of Medicine, Mie, Japan

Craig Slingluff, University of Virginia Health System, Charlottesville, VA

Jacqueline Smith, Dartmouth Medical College, Lebanon, NH

Daniel Speiser, Ludwig Institute for Cancer Research, Hospital Orthopedique, Lausanne, Switzerland

Diane Swanlund, Biomira Inc., Edmonton, Canada

Michael Vajdy, Chiron Corporation, Emeryville, CA

Annegret Van der Aa, Innogenetics NV, Ghent, Belgium

Jeffrey Weber, Norris Comprehensive Cancer Center, USC, Los Angeles CA

Thomas Woelfel, Johann-Gutenberg University Mainz, Germany

Jedd Wolchok, Memorial Sloan-Kettering Cancer Center, New York, NY





References
1.
Asai
T

Storkus
WJ

Whiteside
TL


Evaluation of the modified ELISPOT assay for gamma interferon production in cancer patients receiving antitumor vaccines
Clin Diagn Lab Immunol
2000
7
145
154
10.1128/CDLI.7.2.145-154.2000

10702485


2.
Britten CM, Gouttefangeas C, Schoenmaekers-Welters MJP, Pawelec G, Koch S, Ottensmeier C, Mander A, Walter S, Paschen A, Müller-Berghaus J, Haas I, Mackensen A, Køllgaard T, Thor Straten P, Schmitt M, Giannopoulos K, Maier R, Veelken H, Bertinetti C, Konur A, Huber C, Stevanović S, Wölfel T and Van der Burg SH (2007) The CIMT-monitoring panel: a two-step approach to harmonize the enumeration of antigen-specific CD8+ T lymphocytes by structural and functional assays. Cancer Immunol Immunother (in press). 10.1007/s00262-007-0379-z

3.
http://www.zellnet.com/february2005/


4.
Cox
JH

Ferrari
G

Bailer
RT

Koup
RA


Automating procedures for processing, cryopreservation, storage and manipulation of human peripheral mononuclear cells
J Assoc Lab Automat
2004
9
16
23
10.1016/S1535-5535(03)00202-8

Cox JH, Ferrari G, Bailer RT, Koup RA (2004) Automating procedures for processing, cryopreservation, storage and manipulation of human peripheral mononuclear cells. J Assoc Lab Automat 9:16–23 

5.
Cox
JH

Ferrari
G

Kalams
SA

Lopaczynski
W

Oden
N

D’Souza
MP

Elispot Collaborative Study Group

Results of an ELISPOT proficiency panel conducted in 11 laboratories participating in international human immunodeficiency virus type 1 vaccine trials
AIDS Res Hum Retroviruses
2005
21
68
81
10.1089/aid.2005.21.68

15665646


6.
Cox
JH

Ferrari
G

Janetzki
S


Measurement of cytokine release at the single cell level using the ELISPOT assay
Methods
2006
38
274
282
10.1016/j.ymeth.2005.11.006

16473524


7.
Currier
JR

Kuta
EG

Turk
E

Earhart
LB

Loomis-Price
L

Janetzki
S

Ferrari
G

Birx
DL

Cox
JH


A panel of MHC class I restricted viral peptides for use as a quality control for vaccine trial ELISPOT assays
J Immunol Methods
2002
260
157
172
10.1016/S0022-1759(01)00535-X

11792386


8.
Dubey
S

Clair
J

Fu
T-M

Guan
L

Long
R

Mogg
R

Anderson
K

Collins
KB

Gaunt
C

Fernandez
VR

Zhu
L

Kierstead
L

Thaler
S

Gupta
SB

Straus
W

Mehrotra
D

Tobery
TW

Casimiro
DR

Shiver
JW


Detection of HIV vaccine-induced cell-mediated immunity in HIV-seronegative clinical trial participants using an optimized and validated enzyme-lined immunospot assay
J Acquir Immune Defic Syndr
2007
45
20
27
10.1097/QAI.0b013e3180377b5b

17310936


9.
http://www.fda.gov/cder/guidance/ichq2a.pdf


10.
Findlay Smith
JWA; WC

Lee
JW

Nordblom
GD

Das
I

DeSilva
BS

Khan
MN

Bowsher
RR


Validation of immunoassays for bioanalysis: a pharmaceutical industry perspective
J Pharm Biomed Anal
2000
21
1249
1273
10.1016/S0731-7085(99)00244-7

10708409


11.
Hobeika
AC

Morse
MA

Osada
T

Ghanayem
M

Niedzwiecki
D

Barrier
R

Lyerly
HK

Clay
T


Enumerating antigen-specific T-cell responses in peripheral blood
J Immunother
2005
28
63
72
10.1097/00002371-200501000-00008

15614046


12.
Hoos
A

Parmiani
G

Hege
K

Sznol
M

Loibner
H

Eggermont
A

Urba
W

Blumenstein
B

Sacks
N

Keilholz
U

Nichol
G

Cancer Vaccine Clinical Trial Working Group

A clinical development paradigm for cancer vaccines and related biologics
J Immunother
2007
30
1
15
10.1097/01.cji.0000211341.88835.ae

17198079


13.
http://www.fda.gov/cber/gdlns/ichq2bmeth.pdf


14.
Janetzki
S


Automation of the Elispot technique: past, present and future
J Assoc Lab Automat
2004
9
10
15
10.1016/S1535-5535(03)00084-4

Janetzki S (2004) Automation of the Elispot technique: past, present and future. J Assoc Lab Automat 9:10–15 

15.
Janetzki
S

Schaed
S

Blachere
NE

Ben-Porat
L

Houghton
AN

Panageas
KS


Evaluation of Elispot assays: influence of method and operator on variability of results
J Immunol Methods
2004
291
175
183
10.1016/j.jim.2004.06.008

15345315


16.
Janetzki
S

Cox
JH

Oden
N

Ferrari
G


Standardization and validation issues of the ELISPOT assay
Methods Mol Biol
2006
302
51
86

15937345


17.
Keilholz
U

Weber
J

Finke
JH

Gabrilovich
DI

Kast
WM

Disis
ML

Kirkwood
JM

Scheibenbogen
C

Schlom
J

Maino
VC

Lyerly
HK

Lee
PP

Storkus
W

Marincola
F

Worobec
A

Atkins
MB


Immunologic monitoring of cancer vaccine therapy: results of a workshop sponsored by the Society for Biological Therapy
J Immunother
2002
25
97
138
10.1097/00002371-200203000-00001

12074049


18.
Kierstead
LS

Dubey
S

Meyer
B

Tobery
TW

Mogg
R

Fernandez
VR

Long
R

Guan
L

Gaunt
C

Collins
K

Sykes
KJ

Mehrotra
DV

Chirmule
N

Shiver
JW

Casimiro
DR


Enhanced rates and magnitude of immune responses detected against an HIV vaccine: effect of using an optimized process for isolating PBMC
AIDS Res Hum Retroviruses
2007
23
86
92
10.1089/aid.2006.0129

17263637


19.
Lathey
J


Preliminary steps toward validating a clinical bioassay
BioPharm Int
2003
16
42
50

Lathey J (2003) Preliminary steps toward validating a clinical bioassay. Biopharm Int 16:42–50 

20.
Lathey JL, Martinez K, Gregory S, D’Souza P, Lopaczynski W (2005) Characterization of assay variability in real-time and batch assays of sequential samples from the same donors. FOCIS 5th Annual Meeting, Poster, Abstract# Su2.96

21.
Lem L (2003) Cell counting and viability assessments in the process development of cellular therapeutics. BioProcessing J July/August:57–60

22.
Maecker
T


Disis
ML


The role of immune monitoring in evaluating cancer immunotherapy
Cancer drug discovery and development: immunotherapy of cancer
2005
NJ
Humana Press Inc
59
72

Maecker T (2005) The role of immune monitoring in evaluating cancer immunotherapy. In: Disis ML (ed) Cancer drug discovery and development: immunotherapy of cancer. Humana Press Inc., NJ, pp 59–72 

23.
Maecker
HT

Dunn
HS

Suni
MA

Khatamzas
E

Pitcher
CJ

Bunde
T

Persaud
N

Trigona
W

Fu
TM

Sinclair
E

Bredt
BM

McCune
JM

Maino
VC

Kern
F

Picker
LJ


Use of overlapping peptide mixtures as antigens for cytokine flow cytometry
J Immunol Methods
2001
255
27
40
10.1016/S0022-1759(01)00416-1

11470284


24.
Morse
MA

Clay
TM

Hobeika
AC

Mosca
PJ

Lyerly
HK


Surrogate markers of response to cancer immunotherapy
Expert Opin Biol Ther
2001
1
153
158
10.1517/14712598.1.2.153

11727526


25.
Mwau
M

McMichael
AJ

Hanke
T


Design and validation of an enzyme-linked immunospot assay for use in clinical trials of candidate HIV vaccines
AIDS Res Hum Retroviruses
2002
18
611
618
10.1089/088922202760019301

12079556


26.
Nagorsen
D

Scheibenbogen
C

Thiel
E

Keilholz
U


Immunological monitoring of cancer vaccine therapy
Expert Opin Biol Ther
2004
4
1677
1684
10.1517/14712598.4.10.1677

15461579


27.
NCCLS (2001) Evaluation of matrix effects, approved guidelines. NCCLS document EP14-A

28.
NCCLS (2004) Performance of single cell immune response assays; approved guidelines. NCCLS document I/LA26-A

29.
http://www.niaid.nih.gov/hivvaccines/validation.htm


30.
http://www.fda.gov/cber/summaries/120600bio10.ppt


31.
Russell
ND

Hudgens
MG

Ha
R

Havenar-Daughton
C

McElrath
MJ


Moving to human immunodeficiency virus type 1 vaccine efficacy trials: defining T cell responses as potential correlates of immunity
J Infect Dis
2003
187
226
242
10.1086/367702

12552447


32.
Samri
A

Durier
C

Urrutia
A

Sanchez
I

Gahery-Segard
H

Imbart
S

Sinet
M

Tartour
E

Aboulker
J-P

Autran
B

Venet
A

The ANRS Elispot Standardization Group

Evaluation of the interlaboratory concordance in quantification of HIV-specific T cells with a gamma interferon enzyme-linked immunospot assay
Clin Vaccine Immunol
2006
13
684
697
10.1128/CVI.00387-05

16760328


33.
Scheibenbogen
C

Romero
P

Rivoltini
L

Herr
W

Schmittel
A

Cerottini
J-C

Woelfel
T

Eggermont
AMM

Keilholz
U


Quantitation of antigen-reactive T cells in peripheral blood by IFNg-ELISPOT assay and chromium-release assay: a four-centre comparative trial
J Immunol Methods
2000
244
81
89
10.1016/S0022-1759(00)00257-X

11033021


34.
Smith
JG

Liu
X

Kaufhold
RM

Clair
J

Caulfield
MJ


Development and validation of a gamma Interferon ELISPOT assay for quantitation of cellular immune responses to varicella-zoster virus
Clin Diagn Lab Immunol
2001
8
871
879
10.1128/CDLI.8.5.871-879.2001

11527795


35.
Smith
JG

Joseph
HR

Green
T

Field
JA

Wooters
M

Kaufhold
RM

Antonello
J

Caulfield
MJ


Establishing acceptance criteria for cell-mediated-immunity assays using frozen peripheral blood mononuclear cells stored under optimal and suboptimal conditions
Clin Vaccine Immunol
2007
14
527
537
10.1128/CVI.00435-06

17376862


36.
Tuomela
M

Stanescu
I

Krohn
K


Validation overview of bio-analytical methods
Gene Ther
2005
12
Suppl 1
131
138
10.1038/sj.gt.3302627

Tuomela M, Stanescu I, Krohn K (2005) Validation overview of bio-analytical methods. Gene Ther 12(Suppl 1):131–138 

37.
United States Pharmacopeia—USP (1999) Validation of compendial methods. Suppl 10, pp 5059–5062

38.
Walker
EB

Disis
ML


Monitoring immune responses in cancer patients receiving tumor vaccines
Int Rev Immunol
2003
22
283
319
10.1080/08830180305226

12745643


39.
Whiteside
TL


Immunologic monitoring of clinical trials in patients with cancer: technology versus common sense
Immunol Invest
2000
29
149
162

10854184



Abbreviations
CVC/SVI
Cancer Vaccine Consortium of the Sabin Vaccine Institute


PBMC
Peripheral blood mononuclear cells


CEF
C
E
f
luenza virus


CMV
Cytomegalie virus


NIAID
National Institute of Allergy and Infectious Diseases


CV
Coefficient of variation


SOP
Standard operating procedure




Authors Sylvia Janetzki, Katherine S. Panageas, Jean Boyer, Cedrik M. Britten, Timothy M. Clay, Michael Kalos, Holden T. Maecker, Pedro Romero, Jianda Yuan are members of Steering Committee of the CVC Immune Assay Working Group. W. Martin Kast and Axel Hoos are members of the Executive Council of the CVC.
CVC Elispot Proficiency Panel members are listed alphabetically in Appendix.
This manuscript is published in association with the original article “The CIMT-Monitoring panel: A two-step approach to harmonize the enumeration of antigen-specific CD8+ T lymphocytes by structural and functional assays” by C. M. Britten et al. and a commentary by C. M. Britten, S. Janetzki et al.: “Toward the harmonization of immune monitoring in clinical trials - Quo vadis?”.




