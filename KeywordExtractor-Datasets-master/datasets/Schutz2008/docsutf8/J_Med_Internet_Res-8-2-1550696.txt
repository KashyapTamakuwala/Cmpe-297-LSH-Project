J Med Internet Res
Journal of Medical Internet Research
1438-8871
Gunther Eysenbach
Centre for Global eHealth Innovation, Toronto, Canada


1550696
v8i2e6
16867969
10.2196/jmir.8.2.e6
Original Paper


Health Information Literacy and Competencies of Information Age Students: Results From the Interactive Online Research Readiness Self-Assessment (RRSA)

Ivanitskaya
Lana

PhD
Assistant Professor
1205 Health Professions Building
Central Michigan University
Mt. Pleasant, MI 48859
USA
+1 989 774 1639
+1 989 774 2888
ivani1sv@cmich.edu

1

O’Boyle
Irene

PhD
CHES
1

Casey
Anne Marie

1


1
Central Michigan University
Mt. Pleasant, MI
USA

McLeroy
Kenneth


Simms
Michelle



Apr–Jun
2006

21
4
2006

8
2
e6
26
12
2005

13
1
2006

06
2
2006

10
2
2006


© Lana Ivanitskaya, Irene O’Boyle, Anne Marie Casey.  Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 21.4.2006.  Except where otherwise noted, articles published in the Journal of Medical Internet Research are distributed under the terms of the Creative Commons Attribution License (http://www.creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited, including full bibliographic	details and the URL (see "please cite as" above), and this statement is included.
2006

Background
 In an era of easy access to information, university students who will soon enter health professions need to develop their information competencies. The Research Readiness Self-Assessment (RRSA) is based on the Information Literacy Competency Standards for Higher Education, and it measures proficiency in obtaining health information, evaluating the quality of health information, and understanding plagiarism.

Objective
 This study aimed to measure the proficiency of college-age health information consumers in finding and evaluating electronic health information; to assess their ability to discriminate between peer-reviewed scholarly resources and opinion pieces or sales pitches; and to examine the extent to which they are aware of their level of health information competency.

Methods
 An interactive 56-item online assessment, the Research Readiness Self-Assessment (RRSA), was used to measure the health information competencies of university students. We invited 400 students to take part in the study, and 308 participated, giving a response rate of 77%. The RRSA included multiple-choice questions and problem-based exercises. Declarative and procedural knowledge were assessed in three domains: finding health information, evaluating health information, and understanding plagiarism. Actual performance was contrasted with self-reported skill level. Upon answering all questions, students received a results page that summarized their numerical results and displayed individually tailored feedback composed by an experienced librarian.

Results
 Even though most students (89%) understood that a one-keyword search is likely to return too many documents, few students were able to narrow a search by using multiple search categories simultaneously or by employing Boolean operators. In addition, nearly half of the respondents had trouble discriminating between primary and secondary sources of information as well as between references to journal articles and other published documents. When presented with questionable websites on nonexistent nutritional supplements, only 50% of respondents were able to correctly identify the website with the most trustworthy features. Less than a quarter of study participants reached the correct conclusion that none of the websites made a good case for taking the nutritional supplements. Up to 45% of students were unsure if they needed to provide references for ideas expressed in paraphrased sentences or sentences whose structure they modified. Most respondents (84%) believed that their research skills were good, very good, or excellent. Students’ self-perceptions of skill tended to increase with increasing level of education. Self-reported skills were weakly correlated with actual skill level, operationalized as the overall RRSA score (Cronbach alpha = .78 for 56 RRSA items).

Conclusions
 While the majority of students think that their research skills are good or excellent, many of them are unable to conduct advanced information searches, judge the trustworthiness of health-related websites and articles, and differentiate between various information sources. Students’ self-reports may not be an accurate predictor of their actual health information competencies.


Health information
electronic health information
evaluation of electronic resources
electronics
telecommunications
consumer health information
patient education
educational status
computer network



Introduction
Background and Purpose of the Study
1
2
3
]. In addition, it aims at providing needs assessment information that may aid in accomplishing Objective 11-3, which is related to increasing the proportion of health communication activities that include research and evaluation, and Objective 11-4, set to increase the proportion of health-related websites that disclose information that can be used to assess the quality of the sites.
4
5
6
8
].
Internet users may tend to underestimate the effort and competence required for obtaining trustworthy health information. A decade ago, communication researchers who compared print and television media described this paradox:
could
9
].

minimum
average
 effort required to sift through the gigabytes of information in order to sort out the most credible documents, or at least those that appear as such.
Higher education institutions in the United States provide access to an unprecedented quantity of digital information via library archives, licensed online databases, and the public-access Internet. To differentiate between publicly accessible Web documents and password-protected scholarly databases, which can be accessed by paid members via the Web, we refer to the former as the “the public-access Internet.”
Our study explores three basic questions: How proficient are university students at finding and evaluating health-related information? How well do they understand the difference between peer-reviewed scholarly resources and opinion pieces or sales pitches? How aware are they of their own level of health information competencies? The main goal of this project was to identify approaches to building Information Age competencies of young health consumers, specifically a cohort of 18- to 23-year-old students enrolled in higher education programs.

Literature Review: Health Information and the Internet
3
10
14
10
15
16
17
17
].
18
10
15
].
19
20
]. The theoretical framework for this study is largely based on the information processing theories and concepts discussed below.
21
controlled processing
automatic processing
 of information that has greater capacity, for example, when several tasks can be done at the same time. Automaticity requires less attentional resources than controlled processing, and it is developed through extensive practice under the condition of consistent stimuli and response requirements. When surfing the Internet, for example, health information consumers limit their exposure to inconsistent conditions—they tend to use the same search engines and the same searching methods, such as entering keywords into the nonadvanced search window. The assessment of health information competencies in this study incorporates tasks that call for automatic processing and tasks where stimuli and response requirements of the task are inconsistent with most health information consumers’ information search practices.
22
23
24
22
23
proceduralization
composition
24
]. Declarative and procedural knowledge are discussed in greater depth in the Methods section.

An Interdisciplinary Research Partnership
25
26
27
28
29
30
], whereas university libraries also serve as gateways to scholarly health materials that are not available on the public-access Internet. In addition to public-access health resources available online, this research focuses on scholarly health resources in academic libraries and their use by students who are training to become health professionals.


Methods
Participants
A sample of 400 college-age students was selected because this cohort is the first Information Age generation that has been exposed, for up to one-half of their lives, to the Internet. Students enrolled in three courses in the College of Health Sciences at a Midwestern university were invited to participate in the study. The first class was a high-enrollment introductory course on the determinants of health. Although only undergraduate students (n = 354) participated in this course, they represented all levels of undergraduates—freshman (59%), sophomores (22%), juniors (9%), and seniors (10%). The second class was an advanced course in health administration in which both undergraduate (n = 19) and graduate students (n = 3) were enrolled. The third class was a mid-level health education course (n = 25) for undergraduate students. All students enrolled in the advanced health administration course and the mid-level health education course were majoring in health professions. About one third of the introductory course students with declared majors were majoring in a health-related discipline, and 31% of students had not made up their minds about a major field of study.
Introductory course students completed the assessment for extra credit, while others did it to learn more about their own skills. The instructors emphasized that the purpose of the assessment was to help students become competent consumers of health-related information.

Measures
Health Information Competencies
2
31
foundational
31
research
 in the assessment’s title matches the language commonly used by the lay population, as in “going to Google to research a health topic,” which is indicative of such behaviors as searching, judging, and making decisions.
31
].
32
]. Declarative knowledge questions in the RRSA measure knowledge of plagiarism, health information sources, and research-related terminology. For example, the following item is used to measure knowledge of research-related terminology:
an annotated list of references used in the article

a summary of the article’s content

a summary of other research on this topic

a note or paragraph about the authors of the article

a glossary of abstract concepts included in the researcher’s model




32
and, or, not
):
stress
medical
. Click here to begin your search [a hyperlink to an interactive online module similar to searches in health-related library databases, such as Medline, with text fields for entering key words and a choice of Boolean operators]. Report the number of documents you found: a) 255; b) 555; c) 700; d) 1164; e) 55164.

In addition, students evaluate the quality of research publications, make judgments about website trustworthiness, and detect plagiarism. For example, the following item is used to measure evaluation of the trustworthiness of websites:
You are looking for information on various nutritional supplements. You found three websites. Click on the links below to examine each site and to evaluate its content. Which of these websites is the most trustworthy? a) cognitogenic aids [a hyperlink]; b) dormitogenic aids [a hyperlink]; c) vescorogenic (gustatogenic) aids [a hyperlink].


Instrument Piloting and Validation
To pilot test an earlier version of the RRSA instrument and to gather initial evidence about its validity and reliability, we administered a 60-item assessment to undergraduates (n = 100) and doctoral students (n = 45), as well as professional librarians (n = 5) and health professionals (n = 3). The feedback from librarians and health professionals offered preliminary evidence in support of the instrument’s face validity and content validity. Specifically, the librarians confirmed that the items included in the RRSA assessment conformed to the Information Literacy Competency Standards and addressed knowledge and skills important to health information consumers. The wording of several items, both stems and response options, was revised based on librarians’ recommendations. In addition, the librarians completed the assessment themselves. Their scores were then compared to the scores of students at two academic levels, undergraduate and doctoral. The results indicated that individuals with greater training and experience in managing digital health information performed better than individuals with less experience. Undergraduate students’ overall scores were the lowest (about 66% correct responses), followed by doctoral students’ scores (73%) and librarians’ scores (95%). These results offer preliminary evidence of the assessment’s criterion-related validity. The pilot test indicated an acceptable internal consistency value (Cronbach alpha > .70), although it could be improved (approach .80) if four items were removed. Therefore, four RRSA items that reduced the overall internal consistency were deleted.
The revised assessment contains 56 items, including 16 multiple-choice questions and 40 true/false questions grouped under 7 stems (Multimedia Appendix 1). For example, knowledge of information sources is measured by a stem that states, “Which of these citations are to journal articles?” The participants then check all that apply from the list of 6 true/false items (3 references to journal articles, 1 book reference, and 1 book chapter reference). Items are scored as +1 if the answer is a correct positive or a correct negative and +0 if the answer is a false positive or a false negative. Further description of the development of the stimulus materials used in website evaluation appears in the Results section, under Proficiency in Evaluating Health Information.
The RRSA assessment was designed to be useable by more than one institution. Its content can be adapted to the needs of various educational programs. Specifically, instructions to participants, the text of individual questions, detailed feedback, links to additional resources, and disclaimers (e.g., about participants’ rights and how the information they provide will be used) can be revised, without help from programmers, using the password-protected online control panel. This has been done by three US universities and one Canadian university that adopted the RRSA for use in their academic programs. For example, all four institutions revised search questions to enable their students to search for documents in their own university’s library catalog. The original RRSA designers provide coaching and training in order to ensure that the changes made to the RRSA do not have a negative impact on its reliability and validity. Ongoing validation studies provide a quality control mechanism and allow the testing of new or revised questions suggested by the partner institutions. The administration of the RRSA to partner institutions is supported through grants, partner donations, and volunteer efforts by the RRSA design team members.


Other Measures
We asked the study participants to share information about their age, gender, and education. Self-reported level of research skills was measured with a single item, “How do you rate your research skills?” with six response options ranging from 1 (nonexistent) to 6 (excellent).

Procedures
The RRSA instrument was administered online. Each student was issued a unique pass to access RRSA questions. The students had the option of submitting an incomplete survey and then returning to it at a later time to finish the remaining questions. This feature promoted better information processing and relieved the students from the need to rush and finish the entire assessment on their first attempt. The average estimated RRSA completion time was 26 minutes. Upon answering all questions, the students received an individualized results page that summarized their performance in different areas by providing a score, a maximum possible score, and percent attained. In addition to the numerical RRSA results, the Web page displayed individually tailored feedback composed by an experienced librarian. The Web page was programmed to compare, within each performance category, each individual student’s performance to the performance of a norm group. In accordance with the student’s competency level, the feedback provided suggestions for skill improvement and an explanation of factors that may have contributed to low, average, or high performance in each area. Finally, students who completed the RRSA were given the option to request additional materials for remedial learning, such as an explanation of the difference between scholarly and nonscholarly resources. The links to these additional materials were delivered to students via email.

Data Analyses
Descriptive statistics were used to examine respondents’ performance in four areas—searching for health-related information, understanding plagiarism, evaluating health information, and self-reported skill level. To examine the relationship between self-reported skill level and actual performance, we computed composite scores. A composite overall score, which is indicative of the health information competency level, was created by adding points for 56 items, which were either true/false or multiple choice. Composite score calculations were preceded by an internal consistency reliability analysis that determined the appropriateness of combining responses from multiple items. We used a Spearman correlation to assess the relationship between the actual skill level (overall score) and self-reported skill level. A multiple regression analysis was used to examine the relationship between actual performance and perceived skill while holding the amount of education (number of credit hours earned) constant.


Results
Our research questions were the following: How proficient are university students at searching for and evaluating health-related information? How well do they understand the difference between peer-reviewed scholarly resources and opinion pieces or sales pitches? How aware are they of their own level of health information competencies? The results for each question are presented below, preceded by a sample description.
Respondent Characteristics
t
400
P
 = .02). Freshmen were slightly more likely not to participate in the RRSA than seniors; the participant group included 7% less freshmen and 10% more seniors than the nonparticipant group. Most respondents were female (77%) and between 18 and 23 years of age (95%). The vast majority of respondents (98%) did not have a bachelor’s degree, and the remaining students were working toward their master’s degrees. Because we administered the RRSA to students in health professions courses, over one third of respondents were majoring in health sciences. Common majors were athletic training and sports medicine, health administration, physical education, pre-physical therapy, and public health promotion. On average, the undergraduates who participated in the study had completed 40 or fewer semester credit hours of university coursework. A quarter of respondents reported earning over 71 credit hours.

Proficiency in Searching for Health Information
Table 1 summarizes performance in searching for health information. The data indicate that most students recognize common health journal titles and can perform a basic search in a library catalog, for example, by entering an exact book title into the title search. Few students, however, can perform an advanced search for a book when they know the book’s author (with a very common last name), general topic, and publication date. We call this search advanced because imprecise book specifications make it hard to find the book without performing a search that takes into account all or nearly all of the available information.
and
or
not
. Boolean operators are used in most search engines, including those used for navigating the Internet (Google or Yahoo), library databases with scholarly journal articles, and library catalogs. Even though most students (89%) understand that a one-keyword search is likely to return too many documents, few are able to narrow a search by using multiple search categories simultaneously or by employing the Boolean operators. In addition, nearly half of the respondents have trouble discriminating between primary and secondary sources of information, as well as between references to journal articles or other published documents, such as books or book chapters.

Proficiency in Evaluating Health Information
One of the most important markers of a competent health information consumer—critical judgment of information—is assessed in two ways: (1) the first set of questions calls for a review of three full-text articles from journals, and (2) the second set of questions calls for a comparison of three health-related websites.
Table 1
, most respondents can determine the article publication date; it appears at the top of a full-text article. Many respondents can also identify an opinion article. Fewer respondents know how to determine if an article includes a research review and are able to check for the author’s affiliation.
The three Web pages about nutritional supplements are realistic looking interactive screens that appear to be live websites. The content of these mock websites, developed specifically for the RRSA, includes graphics, hyperlinks, and text about nonexistent classes of nutritional supplements—cognitogenics, dormitogenics, and gustatogenics. Each website is dedicated to one class of supplement and explains its purpose (e.g., cognitogenics help people with learning disabilities), prevalence (e.g., “gustatogenic aids have been available in Germany and Canada for over five years”), and safety. Even though the descriptions of nutritional supplements were fictitious, all three websites accurately stated that the US Food and Drug Administration did not evaluate the safety or benefits of these nutritional supplements.
Table 1
Searching and evaluating health information: performance on select measures (n = 308)





Respondents With Correct Answers


n

%



Searching for Health Information


Journal of American Medical Association
 (7)
293
95

Demonstration of a skill in locating a book in a university library catalogue based on its exact title (16)
286
93

Understanding that a one-keyword generic search may return too many documents—an overwhelmingly large number of resources on a variety of topics (4)
275
89

Use of a proper research strategy—thinking about a broad topic to identify a sub-area of interest (2)
268
87

Ability to detect a journal citation that is incomplete—lacks a year of publication (17)
241
78

Understanding of a term “article abstract”—a summary of the article’s content (8)
234
76

Knowledge that a journal is a source of scholarly (analytical) information on a narrowly specialized topic (6)
214
70

Understanding of a term “bibliography”—a list of references or citations (9)
213
69

Identification of a primary source of health information: medical record (14)
195
63

Identification of references to journal articles from a list of references that includes both book references and article references (11)
187
61

Knowledge of a peer-reviewed journal article as an authoritative source of specialized health information (12)
185
60

Identification of a primary source of health information: hospital annual report (14)
173
56

Demonstration of a skill in locating a book in a university library catalogue based on a non-unique authors’ name and a general topic (15)
111
36

and, not, or
) (3)
105
34

and, not, or
) (13)
98
32

Evaluation of Information: Full-Text Journal Articles


Evaluation of journal articles: Identification of an article published prior to year 2000 (22)
248
80

Evaluation of journal articles: Identification of an article based on opinion rather than well-supported evidence (19)
242
79

Evaluation of journal articles: Identification of an article based on a review of existing research (20)
166
54

Evaluation of journal articles: Identification of an article written by an author whose affiliation is unknown (21)
148
48

Evaluation of Information: Websites on Nutritional Supplements


Evidence-based decision-making: Disagree that “all three websites make a good case for taking nutritional supplements” (25)
187
61

Evaluation of health-related websites: Identification of the most trustworthy website (23)
154
50

Evaluation of health-related websites: Ability to identify the purpose of a website—to sell services (24)
42*
46

Evidence-based decision-making: Agree that “none of the websites makes a good case for taking nutritional supplements” (25)
67
22



*
This question was added later, and, therefore, it had a smaller number of respondents (n = 92).

Note: RRSA question numbers are shown in parentheses; see Multimedia Appendix 1 for exact question wording.



11
] draw evaluators’ attention to a website’s features rather than its text), yet it is unclear if health information consumers are able to compare these features across multiple websites.
These standard features, rather than the text content, are intended to differentiate the websites in terms of their credibility. Because all respondents are equally uninformed about the nutritional supplements described in the text, they must attend to other features when making quality-related judgments. This purposeful design was motivated by the desire to avoid the confounding influence of pre-existing knowledge about the subject matter described in the document that is being judged. A good measure of one’s ability to critically evaluate Web pages is being able to disentangle the judgment of a website’s features from the judgment of its content. Study participants may have had preconceived notions about the quality of nutritional supplements depending on their purpose (e.g., cognitogenics are for sleeping disorders and gustatogenics are for appetite suppression). To avoid a possible interaction between the untrustworthy features of a website and the believable description of the nutritional supplement, we asked a group of students (n = 52) to judge the trustworthiness of the supplements’ descriptions presented as Microsoft Word documents rather than as websites. Although the level of trustworthiness was about the same for all nutritional supplement descriptions, the least trusted nutritional supplements were placed on the website with the highest number of untrustworthy features.
11
Table 1
).

Understanding the Difference Between Scholarly Resources and Sales Pitches
Less than half of respondents determined the purpose of the least trustworthy website, which was to sell products and services. The visitors to this .com website are charged for reprints of the content, offered discounted products, and provided with multiple prompts (e.g., a running line) to book a consulting appointment with a private nutritionist who has few relevant qualifications. Customer testimonials posted on this site describe fantastic outcomes achieved within an unrealistically short time frame.
Less than a quarter of study participants reached the correct conclusion that none of the websites made a good case for taking the nutritional supplements, whereas 39% of respondents thought that all three websites made a good case for taking the supplements.

Understanding Plagiarism
Table 2
Table 3
 display responses to sample questions that measure declarative knowledge of plagiarism. They show that many students are aware that common knowledge can be reproduced without references, whereas words written by others should be enclosed in quotation marks and accompanied by a complete reference. But when presented with more ambiguous examples of plagiarism, some study participants demonstrated misconceptions about what constitutes plagiarism. A surprisingly large number of respondents believed that it is appropriate to present another person’s ideas as their own without citing a specific source, especially if this person is a relative or if the original words have been slightly modified.
Table 2
Understanding plagiarism: when references are needed (n = 308)




Which of the following can be reproduced without proper reference? Check all that apply:

Respondents With Correct Positive or Negative Answers


n

%



*

294
96

Hospital board member’s point of view
264
86

My classmate’s ideas
232
75

Unpublished works
223
73

Spoken word
209
68

My dad’s political opinions
156
51



*
Common knowledge can be reproduced without proper reference.

Note: Items are scored as +1 if the answer is a correct positive or a correct negative and +0 if the answer is a false positive or a false negative.



Table 3
Defining plagiarism (n = 308)




Which of the following are plagiarism examples? Check all that apply:

Respondents With Correct Positive or Negative Answers


n

%



*

290
95

*

276
90

Enclosing the word-for-word sentence in quotation marks, accompanied by a citation.
271
88

*

215
70

*

201
65

*

169
55



*
These items are examples of plagiarism..

Note: Items are scored as +1 if the answer is a correct positive or a correct negative and +0 if the answer is a false positive or a false negative.



Health Affairs
33
Table 3
).

Awareness of Personal Health Information Competencies
When asked “How do you rate your research skills overall?” most respondents (84%) believed that their skills were good, very good, or excellent. To compare self-reported and actual skill levels, we computed an overall health information competency score for each participant. An acceptable level of internal consistency reliability (Cronbach alpha = .78) for 56 right/wrong items indicates that it is appropriate to calculate the overall score as the sum of points of these 56 items. The overall scores ranged from 20 to 54 with a mean of 37 (SD = 6.35) and did not significantly depart from a normal distribution.
Table 4
within
 each self-reported skill level. This indicates that the overall health information competency score was high for some students and low for other students, despite the fact that their self-reported competency was the same.
Table 4
Means for health information competency overall score by self-reported skill level





How do you rate your research skills?

n

Mean Overall Score

SD



Nonexistent
0
-
0

Poor
3
36.33
4.04

Fair
47
34.89
5.52

Good
162
36.89
6.29

Very good
83
37.64
6.89

Excellent
13
36.77
6.10

Total
308
36.78
6.35




2

P <
P
 = .23). Overall, the results suggest that although students’ self-ratings of research skills tend to increase with the increasing level of education, these self-reports may not be an accurate predictor of students’ actual health information competencies.


Discussion
Interpretation of Findings
The present study represents a systematic effort to measure health information competencies using a standardized and reliable measurement tool, the Research Readiness Self-Assessment (RRSA). The data were obtained from a diverse sample of 308 respondents (77% response rate). Nonrespondents (n = 92) differed from respondents (n = 308) in terms of their academic level: freshmen were slightly more likely not to participate in the RRSA than higher-level students. The most likely explanation for nonparticipation is a lack of interest in extra credit rather than the computer-assisted administration of the RRSA. It is possible, of course, that students with particularly poor computer skills found the online administration a barrier. However, a semester after we collected the data reported in this paper, there was a 100% participation rate by 180 undergraduates in two introductory courses where the instructors required RRSA completion. The two course instructors reported no student complaints about not being able to follow emailed instructions on how to complete the assessment.
The data indicate that many students lack important competencies that may limit their ability to make informed health choices. We observed deficiencies in the areas of conducting advanced searches, discriminating among different types of information sources, referencing other people’s ideas, and evaluating information from Web pages and journal articles. Our data suggest that undergraduate students are inaccurate judges of their own competencies and hold a very positive view of their ability to do research. This finding may reveal an important barrier to building health information competencies of college-age students.
We found that there is a large competency gap between the average and the best information consumer. An average undergraduate in our sample is able to solve only 68% of problems that are solved by the best performing study participant (an average score of 37 versus a maximum score of 54). Health information competencies are applied to transform health-related information into knowledge that is consistent with the most current medical practice. High competence variability is a proxy indicator of students’ varying ability to make evidence-based decisions. In the past, limited access to information may have prevented health information consumers from acquiring knowledge and making informed choices. The new generation of health information consumers has, for the most part, easy access to information; yet it may not be able to take full advantage of this convenient access.
Our study shows that individuals with limited health information competencies may fail to locate the best available information due to employing poor search strategies. Searches that do not take into account all of the important criteria often produce low-relevancy documents or documents from commercial websites that promote products or services. These sites often present one-sided evidence, which can be detrimental to making a good decision about one’s health. Overall, many students are rather unsophisticated information consumers who rely on basic searchers and the easiest ways of retrieving information.
health
 produces, in less than a second, over 8 million results ordered by popularity (as of June 2005, 25% of these results had .com URLs and 16% had .org or .gov URLs), where a similar search in Medline Plus produces 665 results, organized by health topic. With heavy reliance on public-access Internet search engines, an Information Age generation student may have an inaccurate conception that the Internet is the only place where society stores its best knowledge.
11
14
17
]). Our website evaluation exercise reveals both poor judgment and readiness to follow the lead, even when the authors of the online documents do not explicitly ask for purchase of their products. Although we measured a behavioral intent, rather than an actual behavior, there is still a significant potential for harm, ranging from financial losses to negative health effects, if only a few individuals execute their intent to take nutritional supplements that can be best described as “fake” or “bogus.” As we designed the most trustworthy website for the RRSA, it was alarming to witness the ease of misrepresenting or even falsifying health information. In designing the trustworthy site, we tried to meet as many website evaluation criteria as possible, and it became very apparent that these criteria do not guarantee information accuracy. Even completely false information about nonexistent food supplements can be made to appear trustworthy, as though it comes from an authoritative source.
Indeed, there is no substitute for good judgment when it comes to navigating information. Because this good judgment is a product of both critical thinking and extensive knowledge of the subject matter being researched, we believe that higher education programs are uniquely positioned to develop health information competencies. However, initial work on developing Information Age competencies needs to be done at the K-12 level when children are beginning to be exposed to various sources of information, including the Internet.
34
exact words
ideas
. Similarly, some respondents believe that it is appropriate not to give credit for original ideas that are expressed orally (rather than in writing) or by people whom they know well. If carried into one’s professional life, this misconception can make it difficult to follow ethical norms for recognizing others’ knowledge contributions. Such ethical norms are strong in health professions, and their violation may lead to negative consequences.
9
9
]. The Information Age generation of college students may benefit from this point.

Implications for Health Promotion Practice
35
]. In this study, most registered nurses did not search databases such as Medline or felt skilled to do so. This preliminary evidence suggests that health professionals need to build their health information competencies.
36
computer literacy
informatics awareness
computer experience
. The RRSA assessment used in the present study adds to the literature on health literacy by defining basic knowledge and skills needed for managing electronic health information resources.
Among the limitations of the present study is the narrowly focused sample, which limits our ability to generalize the study’s findings to the broader population of health information consumers. The students from a Midwestern university may not be completely representative of the entire population of US Information Age students, due to, for example, the relatively homogeneous ethnic composition and possible overrepresentation of individuals raised in rural communities. In our future studies, we intend to broaden the pool of RRSA participants by including multiple educational institutions as well as urban and rural communities located in different geographic regions.
In contrast with many health information literacy studies, this research presents the results obtained via direct measure of skills and knowledge rather than via self-reports by health information consumers. While the reliability of the RRSA assessment reaches acceptable levels, it is necessary to further assess its unidimensionality, content validity, and criterion-related validity. A comprehensive validation study of the RRSA instrument is currently under way.

Conclusions
37
]. Health educators must continue to partner with a variety of groups that play an important role in promoting health information literacy, such as librarians and educators.
The assessment tool used in the present study is a self-administered instrument that provides a reliable account of health information competencies related to managing electronic health information. Data acquired through this research can be used to suggest curriculum improvements and estimates of the higher end level of skill held by health information consumers. It can also be used to educate health information consumers about their levels of skill necessary for managing health information from electronic sources. RRSA findings suggest that health information competencies of undergraduate students, many of whom will soon enter a variety of health professions, are limited. Health literacy educators can utilize RRSA findings to design educational interventions that impact information consumers’ skills and prepare them for the challenges of living and working in the Information Age.



The authors would like to thank Aamna Qamar for her assistance in preparing the final copy of this manuscript and Wesley A. Leonard for providing programming support for our research project. This research was completed with support from Central Michigan University’s School of Graduate Studies, University Libraries, and The Herbert H. and Grace A. Dow College of Health Professions.

None declared.


Multimedia Appendix 1
RRSA questions.




Multimedia Appendix 2
Video of the online-administered RRSA instrument.







Multimedia Appendix 3
Powerpoint slides about the RRSA study.





1
Bradley
P

Herrin
J


Development and validation of an instrument to measure knowledge of evidence-based practice and searching skills
Med Educ Online
2004
2006 Apr 8
9
15
http://www.med-ed-online.org/res00096.htm



2
Association of College & Research Libraries
Information literacy competency standards for higher education
2000
2006 Apr 8
Chicago, IL
Association of College & Research Libraries
http://www.ala.org/ala/acrl/acrlstandards/informationliteracycompetency.htm




3
Office of Disease Prevention and Health Promotion
Communicating Health: Priorities and Strategies for Progress
Action Plans to Achieve the Health Communication Objectives in Healthy People 2010
2003
7
2006 Apr 13
http://odphp.osophs.dhhs.gov/projects/HealthComm/




4
Walther
Joseph B

Wang
Zuoming

Loh
Tracy


The effect of top-level domains and advertisements on health web-site credibility


2004
9
3
6
3
e24
15471750
v6e24
10.2196/jmir.6.3.e24
15471750


5
Hogan
Timothy P

Palmer
Carole L


Information preferences and practices among people living with HIV/AIDS: results from a nationwide survey
J Med Libr Assoc
2005
10
93
4
431
9
16239938
16239938


6
Biermann
J S

Golladay
G J

Greenfield
M L

Baker
L H


Evaluation of cancer information on the Internet
Cancer
1999
8
1
86
3
381
90
99357313
10430244


7
Cheh
Julie A

Ribisl
Kurt M

Wildemuth
Barbara M


An assessment of the quality and usability of smoking cessation information on the Internet
Health Promot Pract
2003
7
4
3
278
87
22973147
10.1177/1524839903004003012
14610998


8
Impicciatore
P

Pandolfini
C

Casella
N

Bonati
M


Reliability of health information for the public on the World Wide Web: systematic survey of advice on managing fever in children at home


1997
6
28
314
7098
1875
9
97367429
9224132


9
Solomon
G

Leigh
T


Predispositions about learning from print and television
J Commun
1984
34
4
129
130
10.1111/j.1460-2466.1984.tb02207.x


10
Cline
R J

Haynes
K M


Consumer health information seeking on the Internet: the state of the art
Health Educ Res
2001
12
16
6
671
92
21639062
10.1093/her/16.6.671
11780707


11
Kotecki
JE

Chamness
BE


A valid tool for evaluating health-related WWW sites
J Health Educ
1999
30
1
56
59


12
National Cancer Institute
How to evaluate health information on the Internet: questions and answers
2006 Apr 8
http://www.cancer.gov/cancertopics/factsheet/Information/internet




13
US Food and Drug Administration
Health information on-line
FDA Consumer
1996
6
2006 Apr 8
30
5
http://www.fda.gov/fdac/features/596_info.html#site




14
World Health Organization
Medical products and the Internet: a guide to finding reliable information
1999
Geneva, Switzerland
WHO


15
Eysenbach
Gunther

Powell
John

Kuss
Oliver

Sa
Eun-Ryoung


Empirical studies assessing the quality of health information for consumers on the world wide web: a systematic review
JAMA
2002
287
20
2691
700


jrv10005
22016241
10.1001/jama.287.20.2691
12020305


16
Crespo
J


Training the health information seeker: quality issues in health information web sites
Libr Trends
2004
53
2
360
374


17
Eysenbach
Gunther

Köhler
Christian


How do consumers search for and appraise health information on the world wide web? Qualitative study using focus groups, usability tests, and in-depth interviews
BMJ
2002
3
9
324
7337
573
7


11884321
21881326


18
Hibbard
Judith H

Peters
Ellen


Supporting informed consumer health care decisions: data presentation approaches that facilitate the use of information in choice
Annu Rev Public Health
2003
24
1
413
33
10.1146/annurev.publhealth.24.100901.141005
100901.141005
22553934
12428034


19
Oravec
J A


On the "proper use" of the Internet: self-help medical information and on-line health care
J Health Soc Policy
2001
14
1
37
60
21268684
10.1300/J045v14n01_03
11374297


20
Bensley
RJ

Mercer
N

Brusk
JJ

Underhile
R

Rivas
J

Anderson
J

Kelleher
D

Lupella
M

deJager
AC


The e Health Behavior Management Model: a stage-based approach to behavior change and management
Prev Chronic Dis
2004
10
1
4
http://www.cdc.gov/pcd/issues/2004/oct/04_0070.htm




21
Schneider
W

Schiffrin
RM


Controlled and automatic human information processing: I. Detection, search, and attention
Psychol Rev
1977
84
1
66


22
Anderson
JR


Acquisition of cognitive skill
Psychol Rev
1982
89
4
369
406
10.1037/0033-295X.89.4.369


23
Anderson
JR


Skill acquisition: compilation of weak-method problem solutions
Psychol Rev
1987
94
2
192
210
10.1037/0033-295X.94.2.192


24
Weiss
HM


Learning theory and industrial and organizational psychology. In: M. Dunnette, LM Hough, editors. Handbook of industrial and organizational psychology. 2nd ed. Vol. 2
1990
Palo Alto, CA
Consulting Psychological Press
171
221


25
Kovacs
JK


Why develop web-based health information workshops for consumers?
Libr Trends
2004
53
2
348
359


26
US National Library of Medicine
National Institutes of Health
Medline Plus: Trusted Health Information for You
2006 Apr 8
http://medlineplus.gov/




27
Miller
N

Tyler
RJ

Backus
JEB


Medline Plus: The National Library of Medicine brings quality information to health consumers
Libr Trends
2004
53
2
375
388


28
Linnan
Laura A

Wildemuth
Barbara M

Gollop
Claudia

Hull
Peggy

Silbajoris
Christie

Monnig
Ruth


Public librarians as a resource for promoting health: results from the Health for Everyone in Libraries Project (HELP) librarian survey
Health Promot Pract
2004
4
5
2
182
90
15090172
10.1177/1524839903258018
15090172


29
Connell
E


Designing for diversity
Colorado Libraries
2004
30
1
39
40


30
Detlefsen
EG


Where am I to go? Use of the Internet for consumer health information by two vulnerable communities
Libr Trends
2004
53
2
283
300


31
Ivanitskaya
L

Laus
R

Casey
AM


Research Readiness Self-Assessment (RRSA): assessing students’ research skills and attitudes
J Libr Adm
2004
41
1/2
167
183
10.1300/J111v41n01_13


32
Kraiger
K

Ford
JK

Salas
E


Application of cognitive, skill-based, and affective theories of learning outcomes to new methods of training evaluation
J Appl Psychol Monogr
1993
78
2
311
328
10.1037/0021-9010.78.2.311


33
Lapetina
Elizabeth M

Armstrong
Elizabeth M


Preventing errors in the outpatient setting: a tale of three states
Health Aff (Millwood)
2002
21
4
26
39


22111577
10.1377/hlthaff.21.4.26
12117139


34
Eysenbach
G


Report of a case of cyberplagiarism--and reflections on detecting and preventing academic misconduct using the Internet
J Med Internet Res
                    
2000
3
31
2
1
E4


21577988
10.2196/jmir.2.1.e4
11720923


35
Pravikoff
Diane S

Pierce
Susan T

Tanner
Annelle


Evidence-based practice readiness study supported by academy nursing informatics expert panel
Nurs Outlook
2005
53
1
49
50
15761401
S002965540400154X
10.1016/j.outlook.2004.11.002
15761401


36
Saranto
Kaija

Hovenga
Evelyn J S


Information literacy-what it is about? Literature review of the concept and the context
Int J Med Inform
2004
6
30
73
6
503
13
15171979
10.1016/j.ijmedinf.2004.03.002
S1386505604000632
15171979


37
Birru
Mehret S

Monaco
Valerie M

Charles
Lonelyss

Drew
Hadiya

Njie
Valerie

Bierria
Timothy

Detlefsen
Ellen

Steinman
Richard A


Internet usage by low-literacy adults seeking health information: an observational analysis
J Med Internet Res
                    
2004
9
3
6
3
e25


15471751
v6e25
10.2196/jmir.6.3.e25
15471751



Abbreviations
RRSA
Research Readiness Self-Assessment






