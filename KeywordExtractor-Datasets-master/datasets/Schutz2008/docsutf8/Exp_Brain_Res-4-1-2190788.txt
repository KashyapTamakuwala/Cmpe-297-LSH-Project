Exp Brain Res
Experimental Brain Research. Experimentelle Hirnforschung. Experimentation Cerebrale
0014-4819
1432-1106
Springer-Verlag
Berlin/Heidelberg


2190788
17598092
1012
10.1007/s00221-007-1012-2
Research Article


No effect of auditory–visual spatial disparity on temporal recalibration

Keetels
Mirjam



Vroomen
Jean

+31-13-4662394
+31-13-4662370
j.vroomen@uvt.nl



Department of Psychology, Tilburg University, Warandelaan 2, Tilburg, The Netherlands 

28
6
2007

10
2007

182
4
559
565
4
4
2007

29
5
2007


© Springer-Verlag 2007

It is known that the brain adaptively recalibrates itself to small (∼100 ms) auditory–visual (AV) temporal asynchronies so as to maintain intersensory temporal coherence. Here we explored whether spatial disparity between a sound and light affects AV temporal recalibration. Participants were exposed to a train of asynchronous AV stimulus pairs (sound-first or light-first) with sounds and lights emanating from either the same or a different location. Following a short exposure phase, participants were tested on an AV temporal order judgement (TOJ) task. Temporal recalibration manifested itself as a shift of subjective simultaneity in the direction of the adapted audiovisual lag. The shift was equally big when exposure and test stimuli were presented from the same or different locations. These results provide strong evidence for the idea that spatial co-localisation is not a necessary constraint for intersensory pairing to occur.

Keywords
Intersensory perception
Spatial disparity
Auditory–visual
Temporal order judgment
Temporal recalibration

issue-copyright-statement
© Springer-Verlag 2007




Introduction
1980
1989
1993
1994
1999
1999
1986
1999
2003
2004
2005
2006
2007
). In the present study, we explored the importance of spatial alignment for audio–visual (AV) temporal recalibration.
1999
2001
2003
2004
2005
2006
1999
2003
2006
).
2004
2004
2004
1997
). In this illusion, two visual targets that move across each other can be perceived either to bounce off or to stream through each other. A brief sound presented at the moment that the visual targets coincide generally biases visual perception in favour of a bouncing motion, while without sound observers tend to report a streaming percept. Following exposure to asynchronous sound–light pairs, the optimal delay for obtaining the bounce illusion was shifted in the same direction, but in other conditions, the magnitude of the after-effect was smaller for some of the cross-adaptation conditions.
2006
) demonstrated audio–tactile temporal recalibration by exposing participants to streams of brief auditory and tactile stimuli presented in synchrony, or else with the auditory stimulus leading by 75 ms. Rather than a shift in the PSS, they observed that the JND to resolve audio–tactile temporal order was larger after exposure to the desynchronized streams than after exposure to the synchronous streams. The authors argued that the temporal window for integration was widened due to audio–tactile asynchrony.
1980
1989
1993
1994
1999
1999
2006
2007
1990
differed
 from that of the lights rather than when they came from the same position, thus demonstrating that sound location mattered for auditory grouping, but not intersensory pairing.
2004
). Observing an after-effect following exposure to spatially disparate sound–light pairs would provide strong evidence that spatial co-occurrence is, even at this early stage, not necessary for intersensory pairing to occur. Secondly, the use of an exposure–test design allowed us to introduce a change between the exposure and test stimulus so that we could test whether after-effects generalize to different test stimuli. Here we tested whether spatial similarity between the exposure and test sound affects after-effects. If spatial co-location plays no role in intersensory pairing, one would expect stimulus generalization across space to be complete.

Method
Participants
Thirty students from Tilburg University received course credits for their participation. All reported normal hearing and normal or corrected-to-normal vision. They were tested individually and were unaware of the purpose of the experiment. The study was carried out along the principles laid down in the Helsinki Declaration and informed consent from the participants was obtained.

Stimuli
2
1
Fig. 1
a
c
b
d
negative values
a
b
c
d
 )





Design
Three within-subjects factors were used: exposure lag during the exposure phase (−100 and +100 ms, with negative values indicating that the sound was presented first), location of the sound during exposure (exposure-sound central or lateral) and SOA between the sound and light of the test stimuli (−240, −120, −90, −60, −30, 0, +30, +60, +90, +120, and +240 ms, with negative values indicating that the sound came first). The location of the test sound (central or lateral) was a between-subjects variable. Half of the participants were tested with central test sounds, the other with lateral test sounds. These factors yielded 44 equi-probable conditions for each location of the test sound (2 × 2 × 11), each presented 12 times for a total of 528 trials. Trials were presented in eight blocks of 66 trials each. The exposure lag and the location of the exposure sound were constant within a block, while the SOA between sound and light varied randomly. The order of the blocks was counterbalanced across participants. In half of the blocks with a lateral exposure sound, the sound came from the left, in the other half from the right. The lateral test sounds were presented from the same side as during exposure.

Procedure
Each block started with an exposure phase consisting of 240 repetitions (∼3 min) of a sound–light stimulus pair (ISI = 750 ms) with a constant lag (−100 or +100 ms) between the sound and the light. After a 2,500 ms delay, the first test trial then started. To ensure that participants were fixating the light during exposure, they had to detect the occasional occurrence of the offset (150 ms) of the fixation light (i.e., a catch trial). Participants then pushed a special button.
The test phase consisted of two parts: a short AV re-exposure phase followed by three AV test trials of which the temporal order of the sound and light had to be judged. The re-exposure phase consisted of a train of ten sound-light pairs with the same lag, ISI, and sound location as used during the immediately preceding exposure phase. After 1 s, the three AV test trials were presented with a variable SOA between the sounds and lights. The participant’s task was to judge whether the sound or the light of the test stimulus was presented first. An unspeeded response was made by pressing one of two designated keys on a response box. The next test stimulus was presented 500 ms after a response, and the re-exposure phase of the next trial started 1,000 ms after the response on the third test stimulus.
To acquaint participants with the TOJ task, experimental blocks were preceded by four practice blocks in which no exposure preceded the test trials. The first two practice blocks were to acquaint participants with the response buttons, and consisted of 16 trials in which only the largest SOAs were presented (±240 and ±120). During this part, participants received verbal feedback (“correct” or “wrong”) about whether they gave the correct response or not. The next two practice blocks consisted of 66 trials in which all SOAs were presented 6 times randomly without verbal feedback. Total testing lasted approximately 2.5 h.


Results
Trials of the practice session were excluded from analyses. The proportion of “light-first” responses was for each participant calculated for each combination of exposure lag (−100, +100 ms), location of the exposure sound (central, or lateral), location of the test sound (central, or lateral) and SOA (ranging from −240 to +240 ms). Performance on catch trials was flawless, indicating that participants were indeed looking at the fixation light during exposure. For each combination of exposure lag, location of the exposure sound and location of the test sound, an individually determined psychometric function was calculated over the SOAs by fitting a cumulative normal distribution using maximum likelihood estimation. The mean of the resulting distribution (the interpolated 50% crossover point) is the point of subjective simultaneity (henceforth the PSS), and the slope is a measure of the sharpness with which stimuli are distinguished from one another. The slope is inversely related to the just noticeable difference (JND) and represents the interval (absolute SOA) at which 25 and 75% visual-first responses were given.
2
1
Fig. 2
V-first
) for each exposure lag (−100 ms sound-first, 100 ms light-first) for each combination of location of exposure sound (central, lateral) and location of the test sound (central, lateral)



Table 1
Mean points of subjective simultaneity (PSSs) in ms, and mean just noticeable differences (JND) in parentheses

Location test sound 
Location of the exposure sound

Central 
Lateral

AV-lag (ms)
PSS (JND)
TRE
PSS (JND)
TRE


Central
−100
−12.5 (39.3)
14.5
−9.9 (37.8)
6.4

100
2.0 (40.8)

−3.5 (38.6)


Lateral
−100
6.1 (38.2)
14.2
−14.3 (36.4)
16.8

100
20.3 (36.1)

2.5 (42.0)




Exposure stimulus pairs were presented with an auditory–visual Lag (AV-lag) of −100 and +100 ms with sounds either central or lateral; the location of the test stimulus sound was either central or lateral. The temporal recalibration effect (TRE) reflects the difference in PSSs between the −100 and +100 ms audio–visual lags



P
F
P
1
 shows that the differences between the JNDs (on average 38.7 ms) were rather small and unsystematic.
F
P
F
 < 1). Temporal recalibration thus manifested itself no matter whether exposure sounds came from central or lateral location, and whether the location of the exposure and test sounds was changed or not.

Discussion
2007
2006
) where it was shown that spatial separation does not affect the capturing effect of a light by a sound. Taken together, these findings provide strong evidence that spatial co-occurrence is, even at early perceptual stages, not a necessary constraint for intersensory pairing.
spatial
1966
1978
1978
1981
1994
1999
1994
2001
2003
). Given that we maximized the spatial separation between the sound and light (i.e., at 90 degrees azimuth), and that informal testing indeed confirmed that spatial separation was clearly noticeable, it seems safe to assume that spatial ventriloquism did not diminish the effect of spatial discordance.
1908
2001
2005
2001
2003
2005b
). Our visual task might thus result in a shift of the PSS towards more “visual-first” responses. However, this shift should be uniform for all conditions, and given that temporal recalibration is expressed as a difference in the PSS between exposure lags, the possible role of attention will be subtracted out.
2003
2003
2003a
b
2005a
2005
fused
extra spatial cues
2003
2006
2007
), it seems more likely that the previously observed effects of spatial separation on temporal sensitivity were induced by the availability of redundant spatial cues rather than fusion per se.
1992
2001
). If one accepts that auditory spatial perception evolved for steering vision, but not for deciding whether sound and light belong together, there is no reason why cross-modal interactions would require spatial co-localization. Our results therefore have also important implications for designing multimodal devices or creating virtual reality environments, as they show that the brain can ignore cross-modal discordance in space.


References
Bedford
FL


Constraints on learning new mappings between perceptual dimensions.
J Exp Psychol Hum Percept Perform
1989
15
232
248
10.1037/0096-1523.15.2.232

Bedford FL (1989) Constraints on learning new mappings between perceptual dimensions. J Exp Psychol Hum Percept Perform 15:232–248 

Bertelson
P


The cognitive architecture behind auditory–visual interaction in scene analysis and speech identification
Curr Psychol Cogn
1994
13
69
75

Bertelson P (1994) The cognitive architecture behind auditory–visual interaction in scene analysis and speech identification. Curr Psychol Cogn 13:69–75 

Bertelson
P


Aschersleben
G

Bachmann
T

Musseler
J


Ventriloquism: a case of crossmodal perceptual grouping
Cognitive contributions to the perception of spatial and temporal events
1999
North-Holland
Elsevier
347
363

Bertelson P (1999) Ventriloquism: a case of crossmodal perceptual grouping. In: Aschersleben G, Bachmann T, Musseler J (eds) Cognitive contributions to the perception of spatial and temporal events. Elsevier, North-Holland, pp 347–363 

Bertelson
P

Radeau
M


Cross-modal bias and perceptual fusion with auditory–visual spatial discordance
Percept Psychophys
1981
29
578
584

7279586


Bertelson
P

Aschersleben
G


Temporal ventriloquism: Crossmodal interaction on the time dimension. 1. Evidence from auditory–visual temporal order judgment
Int J Psychophysiol
2003
50
147
155
10.1016/S0167-8760(03)00130-2

14511842


Bertelson
P

Gelder
B


Spence
C

Driver
J


The psychology of multisensory perception
Crossmodal space and crossmodal attention
2004
Oxford
Oxford University Press
141
177

Bertelson P, de Gelder B (2004) The psychology of multisensory perception. In: Spence C, Driver J (eds) Crossmodal space and crossmodal attention. Oxford University Press, Oxford, pp 141–177 

Bregman
AS


Auditory scene analysis
1990
Cambridge, MA
MIT Press

Bregman AS (1990) Auditory scene analysis. MIT Press, Cambridge, MA 

Fendrich
R

Corballis
PM


The temporal cross-capture of audition and vision
Percept Psychophys
2001
63
719
725

11436740


Fujisaki
W

Shimojo
S

Kashino
M

Nishida
S


Recalibration of audiovisual simultaneity
Nat Neurosci
2004
7
773
778
10.1038/nn1268

15195098


Godfroy
M

Roumes
C

Dauchy
P


Spatial variations of visual–auditory fusion areas
Perception
2003
32
1233
1245
10.1068/p3344

14700258


Heffner
RS

Heffner
HE


Visual factors in sound localization in mammals
J Comp Neurol
1992
317
219
232
10.1002/cne.903170302

1577997


Howard
IP

Templeton
WB


Human spatial orientation
1966
Oxford, England
Wiley

Howard IP, Templeton WB (1966) Human spatial orientation. Wiley, Oxford, England 

Keetels
M

Vroomen
J


The role of spatial disparity and hemifields in audio–visual temporal order judgements
Exp Brain Res
2005
167
635
640
10.1007/s00221-005-0067-1

16175363


Keetels M, Stekelenburg JJ, Vroomen J (2007) Auditory grouping occurs prior to intersensory pairing: evidence from temporal ventriloquism. Exp Brain Res (in press)

Kubovy
M

Van Valkenburg
D


Auditory and visual objects
Cognition
2001
80
97
126
10.1016/S0010-0277(00)00155-4

11245841


Morein-Zamir
S

Soto-Faraco
S

Kingstone
A


Auditory capture of vision: examining temporal ventriloquism
Cogn Brain Res
2003
17
154
163
10.1016/S0926-6410(03)00089-2

Morein-Zamir S, Soto-Faraco S, Kingstone A (2003) Auditory capture of vision: examining temporal ventriloquism. Cogn Brain Res 17:154–163 

Murray
MM

Michel
CM

Grave Peralta
R

Ortigue
S

Brunet
D

Gonzalez Andino
S

Schnider
A


Rapid discrimination of visual and multisensory memories revealed by electrical neuroimaging
Neuroimage
2004
21
125
135
10.1016/j.neuroimage.2003.09.035

14741649


Navarra
J

Soto-Faraco
S

Spence
C


Adaptation to audiotactile asynchrony.
Neurosci Lett
2006
413
1
72
76
10.1016/j.neulet.2006.11.027

17161530


Radeau
M


Auditory–visual spatial interaction and modularity
Curr Psychol Cogn
1994
13
3
51

11540554


Radeau
M

Bertelson
P


Cognitive factors and adaptation to auditory–visual discordance
Percept Psychophys
1978
23
341
343

748857


Scheier
CR

Nijhawan
R

Shimojo
S


Sound alters visual temporal resolution
Invest Ophthalmol Vis Sci
1999
40
4169

Scheier CR, Nijhawan R, Shimojo S (1999) Sound alters visual temporal resolution. Invest Ophthalmol Vis Sci 40:4169 

Schneider
KA

Bavelier
D


Components of visual prior entry
Cogn Psychol
2003
47
333
366
10.1016/S0010-0285(03)00035-5

14642288


Sekuler
R

Sekuler
AB

Lau
R


Sound alters visual motion perception
Nature
1997
385
308
308
10.1038/385308a0

9002513


Shore
DI

Spence
C

Klein
RM


Visual prior entry
Psychol Sci
2001
12
205
212
10.1111/1467-9280.00337

11437302


Shore
DI

Spence
C

Klein
RM


Itti
L

Rees
G

Tsotsos
J


Prior entry
Neurobiology of attention
2005
North Holland
Elsevier
89
95

Shore DI, Spence C, Klein RM (2005) Prior entry. In: Itti L, Rees G, Tsotsos J (eds) Neurobiology of attention. Elsevier, North Holland, pp 89–95 

Slutsky
DA

Recanzone
GH


Temporal and spatial dependency of the ventriloquism effect
Neuroreport
2001
12
7
10
10.1097/00001756-200101220-00009

11201094


Spence
C

Shore
DI

Klein
RM


Multisensory prior entry
J Exp Psychol Gen
2001
130
799
832
10.1037/0096-3445.130.4.799

11757881


Spence
C

Baddeley
R

Zampini
M

James
R

Shore
DI


Multisensory temporal order judgments: when two locations are better than one
Percept Psychophys
2003
65
318
328

12713247


Stein
BE

Meredith
MA


The merging of the senses
1993
Cambridge MA
The MIT Press

Stein BE, Meredith MA (1993) The merging of the senses. The MIT Press, Cambridge MA 

Stekelenburg
JJ

Vroomen
J


An event-related potential investigation of the time-course of temporal ventriloquism
Neuroreport
2005
16
641
644
10.1097/00001756-200504250-00025

15812324


Teder-Salejarvi
WA

Di Russo
F

McDonald
JJ

Hillyard
SA


Effects of spatial congruity on audio–visual multimodal integration
J Cogn Neurosci
2005
17
1396
1409
10.1162/0898929054985383

16197693


Titchener
EB


Lectures on the elementary psychology of feeling and attention
1908
New York
Macmillan

Titchener EB (1908) Lectures on the elementary psychology of feeling and attention. Macmillan, New York 

Vroomen
J

Gelder
B


Temporal ventriloquism: sound modulates the flash-lag effect
J Exp Psychol Hum Percept Perform
2004
30
513
518
10.1037/0096-1523.30.3.513

15161383


Vroomen
J

Keetels
M


The spatial constraint in intersensory pairing: no role in temporal ventriloquism
J Exp Psychol Hum Percept Perform
2006
32
1063
1071
10.1037/0096-1523.32.4.1063

16846297


Vroomen
J

Keetels
M

Gelder
B

Bertelson
P


Recalibration of temporal order perception by exposure to audio–visual asynchrony
Cogn Brain Res
2004
22
32
35
10.1016/j.cogbrainres.2004.07.003

Vroomen J, Keetels M, de Gelder B, Bertelson P (2004) Recalibration of temporal order perception by exposure to audio–visual asynchrony. Cogn Brain Res 22:32–35 

Welch
RB


Perceptual modification: adapting to altered sensory environments
1978
New York, NY
Academic

Welch RB (1978) Perceptual modification: adapting to altered sensory environments. Academic, New York, NY 

Welch
RB


Aschersleben
G

Bachmann
T

Müsseler
J


Meaning, attention, and the “unity assumption” in the intersensory bias of spatial and temporal perceptions
Cognitive contributions to the perception of spatial and temporal events
1999
Amsterdam
Elsevier
371
387

Welch RB (1999) Meaning, attention, and the “unity assumption” in the intersensory bias of spatial and temporal perceptions. In: Aschersleben G, Bachmann T, Müsseler J (eds) Cognitive contributions to the perception of spatial and temporal events. Elsevier, Amsterdam, pp 371–387 

Welch
RB

Warren
DH


Immediate perceptual response to intersensory discrepancy
Psychol Bull
1980
88
638
667
10.1037/0033-2909.88.3.638

7003641


Welch
RB

DuttonHurt
LD

Warren
DH


Contributions of audition and vision to temporal rate perception
Percept Psychophys
1986
39
294
300

3737359


Zampini
M

Shore
DI

Spence
C


Audiovisual temporal order judgments
Exp Brain Res
2003
152
198
210
10.1007/s00221-003-1536-z

12879178


Zampini
M

Shore
DI

Spence
C


Multisensory temporal order judgments: the role of hemispheric redundancy
Int J Psychophysiol
2003
50
165
180
10.1016/S0167-8760(03)00132-6

14511844


Zampini
M

Shore
DI

Spence
C


Audiovisual prior entry
Neurosci Lett
2005
381
217
222
10.1016/j.neulet.2005.01.085

15896473


Zampini
M

Guest
S

Shore
DI

Spence
C


Audio–visual simultaneity judgments
Percept Psychophys
2005
67
531
544

16119399





