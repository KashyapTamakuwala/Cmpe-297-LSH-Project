Exp Brain Res
Experimental Brain Research. Experimentelle Hirnforschung. Experimentation Cerebrale
0014-4819
1432-1106
Springer-Verlag
Berlin/Heidelberg


2039806
17632707
1043
10.1007/s00221-007-1043-8
Research Article


Judging surface slant for placing objects: a role for motion parallax

Louw
Stefan

+31-20-5982574
+31-20-5988529
S.Louw@fbw.vu.nl



Smeets
Jeroen B. J.



Brenner
Eli



Faculty of Human Movement Sciences, Vrije Universiteit, Van der Boechorststraat 9, 1081 BT Amsterdam, The Netherlands 

14
7
2007

11
2007

183
2
149
158
14
8
2006

12
6
2007


© Springer-Verlag 2007

People have a variety of sources of information (cues) about surface slant at their disposal. We used a simple placing task to evaluate the relative importance of three such cues (motion parallax, binocular disparity and texture) within the space in which people normally manipulate objects. To do so, we projected a stimulus onto a rotatable screen. This allowed us to manipulate texture cues independently of binocular disparity and motion parallax. We asked people to stand in front of the screen and place a cylinder on the screen. We analysed the cylinder’s orientation just before contact. Participants mainly relied on binocular cues (weight between 50 and 90%), in accordance with binocular cues being known to be reliable when the stimulus surface is nearby and almost frontal. Texture cues contributed between 2 and 18% to the estimated slant. Motion parallax was given a weight between 1 and 9%, despite the fact that it only provided information when the head began to move, which was just before the arm did. Thus motion parallax is used to judge surface slant, even when one is under the impression of standing still.

Keywords
Motion parallax
Texture
Binocular
Cue integration
Cue conflict

issue-copyright-statement
© Springer-Verlag 2007




Introduction
It is often important to accurately judge the slant of surfaces in our nearby environment. Whether placing our foot on the ground when we walk or climb stairs, or our fingers on an object when we grasp it and place it elsewhere, the interaction always involves making contact with surfaces. In order to interact successfully, we need to know the orientation of these surfaces. We have many ways to judge a surface’s orientation, including ones based on texture gradients, binocular disparity and motion parallax.
1995
1994
2003
), so there is reason to expect other cues to also play a role in guiding our actions.
1
1950
1981
1996
2004
1998a
2003
Fig. 1
The deformation of the regular texture of a chess board provides a profound impression that the surface is slanted relative to the plane of the 2D picture




1997
). This assumption holds for a wide variety of natural and artificial objects.
1989
1979
1982
1990
1991
2001
2003
2003
) have shown that motion parallax can guide human movements when binocular cues are not available.
1995
2002
2004
2005
2007
2004
1998b
1993
1994
2005
) measured how binocular cues and texture cues to surface orientation are combined to guide motor behaviour. Cue weights were found to be dependent on surface slant and also on the task: more weight was given to binocular cues for controlling hand movements than for making perceptual judgements. Knill used cue-consistent and cue-conflict stimuli in a virtual reality environment.
2005
). Our main interest was in the extent to which head movements and the resulting motion parallax contribute to the perceived surface slant. So, conditions in which the head could move freely were compared with one in which a head restraint was used. We compared conditions with and without binocular vision in order to be able to evaluate the importance of motion parallax in relation to this cue.

Methods
Participants
Five people, four of whom were male, participated in the experiment. All participants gave their informed consent prior to their inclusion in the study. The experiment was part of an ongoing research program that was approved by the local ethics committee. All participants were right-handed, had normal or corrected-to-normal vision and good binocular vision (stereo acuity <40 arcseconds).

Experimental setup
2
cp
x325
1987
3
3
−2
Fig. 2
right
grey ring
). Participants wore PLATO glasses with which we could switch between no, monocular and binocular vision. During the experiment, only the slanted surface was visible



Fig. 3
left
right
left panel
right panel
grey ring
dark grey
 rim’s shape is in accordance with the texture cue




optotrak 3020
northern digital inc.
, Waterloo, ON, Canada). This system tracks the position of active infrared markers with an accuracy better than 0.5 mm. The 3D-positions of five markers on the probe were tracked at a rate of 200 Hz. The position, orientation and velocity of the probe were calculated from these data.

Procedure
Experiments were performed in a completely dark room. The dark environment and the low intensity of the stimuli ensured that there was no visible external reference frame. Participants were instructed to place the probe at the indicated target position on the surface. They were to start moving as soon as the target was visible. Stimuli were shown for 2.5 s. All movements were completed well within this interval.
In order to avoid dark adaptation a bright lamp was turned on for 5 s immediately after each trial. During this period participants placed the probe at the starting position, 50 cm to the right of the midline of the screen. Then the light was turned off for about 5 s, during which time the experimenter adjusted the orientation of the screen in preparation for the next trial.
4
4
2
3
3
Fig. 4
continuous lines
dashed lines
solid disks
open disks
). The slants have been exaggerated for clarity




We used four conditions in which different combinations of the available cues were presented. The choice of conditions will become clear when we describe the data analysis. We chose three conditions with which we could calculate the five parameters of our model, and one condition to test one of our assumptions.
In the ‘binocular’ condition viewing was binocular and head-free in both conflict and consistent trials. In this condition all cues to slant perception were available. In the ‘monocular’ condition the conflict and consistent trials were both presented monocularly and head-free. Stimuli were viewed with the left or right eye in random order. No binocular cues were available, but all other cues were present. In the ‘biteboard’ condition the head was fixed in combination with monocular viewing. The biteboards were made individually with an impression of the participant’s teeth. The biteboard severely limits head movements, removing information from motion parallax.
In the consistent trials of the ‘mixed’ condition the screen was viewed monocularly (75% of all trials), but in the conflict trials (25%) it was viewed binocularly. This condition was included to evaluate whether participants adapt their strategy at the level of a session rather than per trial. In the ‘binocular’ condition binocular information was always reliable, so participants could have learnt to use this cue. In the ‘mixed’ condition, in contrast, binocular cues were absent in the majority of trials, so participants could have learnt to use texture or motion parallax. Note that the 25% binocular, conflict trials in the ‘mixed’ condition are identical to the conflict trials in the ‘binocular condition’, whereas the 75% consistent trials are identical to the consistent trials in the ‘monocular’ condition. Thus the ‘mixed’ condition serves as a control condition to test whether the weight given to the cues stays about the same under changing viewing conditions on other trials.

Analysis
5
5
Fig. 5
upper left panel
curved thin line
straight thick line
upper right panel
dark-grey
lower panels
 show examples of the probe orientation with time intervals of 25 ms




6
Fig. 6
left panel
right panel
)




1995
i
1
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ {\text{S }} = {\text{ }}\frac{{{\sum\limits_i {w_{i} {\text{ s}}_{i} {\text{ }}} }}} {{{\sum\limits_i {w_{i} {\text{ }}} }}};\quad w_{i} {\text{ }} \propto \frac{1} {{\sigma ^{2}_{i} }}, $$\end{document}

w
i
i
b, m, t, r, p
w
i

w
i

w
i

) will differ between conditions because it depends on the cues that are available in that condition.
2
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ s_{P} = c $$\end{document}


3
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ s_{i} = s $$\end{document}

4
4
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ s_{T} = 10^\circ - s $$\end{document}

5
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ S_{{{\text{consistent}}}} = \frac{{c\;w_{P} + s\;w_{T} + s{\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{{\sum\limits_i {w_{i} } }}} $$\end{document}

6
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ S_{{{\text{conflict}}}} = \frac{{c\;w_{P} + (10^\circ - s)\;w_{T} + s{\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{{\sum\limits_i {w_{i} } }}} $$\end{document}


5
6
6
7
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ \beta _{{{\text{consistent}}}} = \frac{{\partial S_{{{\text{consistent}}}} }} {{\partial s}} = \frac{{\;w_{T} + {\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{{\sum\limits_i {w_{i} } }}} $$\end{document}

8
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ \beta _{{{\text{conflict}}}} = \frac{{\partial S_{{{\text{conflict}}}} }} {{\partial s}} = \frac{{\; - w_{T} + {\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{{\sum\limits_i {w_{i} } }}} $$\end{document}

7
8
9
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ \frac{{\; - w_{T} + {\sum\limits_{i \ne (P,T)} {w_{i} } }}} {{w_{T} + {\sum\limits_{i \ne (P,T)} {w_{i} } }}} = \frac{{\beta _{{{\text{conflict}}}} }} {{\beta _{{{\text{consistent}}}} }} $$\end{document}

10
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ \frac{{w_{P} }} {{w_{T} }} = \frac{{2\beta _{{{\text{consistent}}}} - 2}} {{\beta _{{{\text{conflict}}}} - \beta _{{{\text{consistent}}}} }} $$\end{document}


9
10
11
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ {\left( {\frac{{\beta _{{{\text{conflict}}}} }} {{\beta _{{{\text{consistent}}}} }}} \right)}_{{{\text{binocular}}}} = \frac{{\;w_{B} + w_{M} + w_{R} - w_{T} }} {{w_{B} + w_{M} + w_{R} + w_{T} }} $$\end{document}


w
B

12
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ {\left( {\frac{{\beta _{{{\text{conflict}}}} }} {{\beta _{{{\text{consistent}}}} }}} \right)}_{{{\text{monocular}}}} = \frac{{\;w_{M} + w_{R} - w_{T} }} {{w_{M} + w_{R} + w_{T} }} $$\end{document}


13
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ {\left( {\frac{{\beta _{{{\text{conflict}}}} }} {{\beta _{{{\text{consistent}}}} }}} \right)}_{{{\text{biteboard}}}} = \frac{{\;w_{R} - w_{T} }} {{w_{R} + w_{T} }} $$\end{document}


14
\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{mathrsfs}
\usepackage{upgreek}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
$$ w_{B} + w_{T} + w_{M} + w_{R} + w_{P} = 1 $$\end{document}


w
P

w
T

10
w
P

w
T

11
14
w
B

w
T

w
M

w
R

).
conflict
consistent
) with the matching slopes in the ‘binocular’ and the ‘monocular’ conditions. Data for ‘near’ and ‘far’ target positions were pooled before calculating the slopes. The weights of the cues were calculated for individual participants. In addition, we also pooled the data of all participants before calculating the slopes, which yields the weights for ‘All’ participants.


Results
methods
’ section.
Conditions
7
P
7
P
7
P
10
14
Fig. 7
open symbols
closed symbols
error bars
grey lines
black lines
lower right corner
Asterisks
P
P
 < 0.01)




consistent
P
consistent
conflict
P
conflict
 = 0.72). Thus the weights may not be completely independent of the conditions. The difference was small enough to accept the calculation of the weights on the basis of the assumption that the condition is irrelevant. Our analysis may however underestimate the weight given to the texture cue.

Cue weights
8
Fig. 8
horizontal axis
10
14
. For ‘All’, first all participant’s data in each condition was pooled and then the weights were determined, which are all significantly different from zero. For individual participants the texture cue was not significantly different from zero in one case, the motion cue in four cases and the rest category in three cases





Head movements
Head movements were measured in the monocular viewing condition for three of the participants. Participants move their head considerably when placing the cylinder: EB moved on average 103 mm, JG 53 mm and DdG 37 mm in the lateral direction. Interestingly, the head movement only started just before the arm movement. Shortly before (100 ms) the onset of arm movement (when the probe was 10 mm from the starting position), the head had only moved 10 mm (EB), 4 mm (JG) or 6 mm (DdG). Thus the information from motion parallax is mainly picked up during the arm movement. None of the participants were aware of having made head movements.


Discussion
We used a physically rotatable screen as a surface. The projected stimulus was viewed in a completely dark environment within a space in which objects are normally manipulated. In our analysis systematic deformations that affect a single cue (like depth compression resulting from an erroneous depth estimate) were not considered. Moreover, we assume that the cue weights are the same in all conditions, so that their contributions to the percept only depend on which cues are available. We determined the contributions of binocular disparity, texture cues, motion parallax, a rest category and a prior. Under these conditions and based on these assumptions we conclude that participants mainly relied on binocular information (between 50 and 90%). Texture cues contributed between 2 and 18% to the estimated slant. Motion parallax contributed up to 9%. The prior contributed between 6 and 23%. Residual cues may account for up to 9%.
8
7
). It is not unusual to move the whole body, including the head, when making large arm movements. Beside mechanical reasons for doing so we here show that it may also have perceptual advantages.
1997
2005
). However, artefacts of our setup such as the possible visible micro texture (fibres in the projection foil or pixels on the screen) and the angular distribution of the light scattered from the surface could play a role too. Taken together in a rest category such cues contribute only a few percent to the estimated slant.
7
2004
). Any biases towards a certain orientation of the hand or towards a certain perceived slant will also contribute to the weight of the prior.
2000
1995
2002
2007
 ). It is however possible that the difference arises from less use of motion parallax when binocular information was always available, perhaps because participants move less when there is enough information from other sources than motion parallax. We do not know whether this is the case because we did not measure head movements in all conditions. However, these differences are all too small to be taken seriously without further research.
2003
1998
1999
2003
). It was not known, however, that motion parallax plays a role under conditions where other cues are dominantly available and without actively moving one’s head before starting the action. We conclude that motion parallax is used as a cue to manipulate objects in our nearby environment, even when one is under the impression of holding one’s head still. Motion parallax should therefore not be ignored in a ‘static’ task unless the head is really fixated.


vidi
 grant 452-02-007 of the Netherlands Organization for Scientific Research (NWO). We thank Michael Landy for his suggestions.

References
Buckley
D

Frisby
JP


Interaction of stereo, texture and outline cues in the shape perception of three-dimensional ridges
Vision Res
1993
33
919
933
10.1016/0042-6989(93)90075-8

8506635


Buckley
D

Frisby
JP

Blake
A


Does the human visual system implement an ideal observer theory of slant from texture?
Vision Res
1996
36
1163
1176
10.1016/0042-6989(95)00177-8

8762720


Cuijpers
RH

Smeets
JB

Brenner
E


On the relation between object shape and grasping kinematics
J Neurophysiol
2004
91
2598
2606
10.1152/jn.00644.2003

14749319


Dijkerman
HC

Milner
AD

Carey
DP


Motion parallax enables depth processing for action in a visual form agnosic when binocular vision is unavailable
Neuropsychologia
1999
37
1505
1510
10.1016/S0028-3932(99)00063-9

10617271


Ernst
MO

Banks
MSW

Bülthoff
HH


Touch can change visual slant perception
Nat Neurosci
2000
3
69
73
10.1038/71140

10607397


Gibson
JJ


The perception of visual surfaces
Am J Psychol
1950
63
367
384
10.2307/1418003

15432778


Gillam
B

Rogers
B


Orientation disparity, deformation and stereoscopic slant perception
Perception
1991
20
441
448
10.1068/p200441

1771129


Hibbard
PB

Bradshaw
MF


Reaching for virtual objects: binocular disparity and the control of prehension
Exp Brain Res
2003
148
196
201

12520407


Hillis
JM

Ernst
MO

Banks
MS

Landy
MS


Combining sensory information: mandatory fusion within, but not between, senses
Science
2002
298
1627
1630
10.1126/science.1075396

12446912


Hillis
JM

Watt
SJ

Landy
MS

Banks
MS


Slant from texture and disparity cues: optimal cue combination
J Vis
2004
4
967
992
10.1167/4.12.1

15669906


Hogervorst
MA

Brenner
E


Combining cues while avoiding perceptual conflicts
Perception
2004
33
1155
1172
10.1068/p5253

15693662


Howard
IP

Rogers
BJ


Binocular vision and stereopsis
1995
New York
Oxford University Press

Howard IP, Rogers BJ (1995) Binocular vision and stereopsis. Oxford University Press, New York 

Knill
DC


Surface orientation from texture: ideal observers, generic observers and the information content of texture cues
Vision Res
1998
38
1655
1682
10.1016/S0042-6989(97)00324-6

9747502


Knill
DC


Discrimination of planar surface slant from texture: human and ideal observers compared
Vision Res
1998
38
1683
1711
10.1016/S0042-6989(97)00325-8

9747503


Knill
DC


Reaching for visual cues to depth: the brain combines depth cues differently for motor control and perception
J Vis
2005
5
103
315
10.1167/5.2.2

15831071


Kral
K


Behavioural-analytical studies of the role of head movements in depth perception in insects, birds and mammals
Behav Processes
2003
64
1
12
10.1016/S0376-6357(03)00054-8

12914988


Landy
MS

Graham
N


Chalupa
LM

Werner
JS


Visual perception of texture
The visual neurosciences
2004
Cambridge
MIT Press
1106
1118

Landy MS, Graham N (2004) Visual perception of texture. In: Chalupa LM, Werner JS (eds) The visual neurosciences. MIT Press, Cambridge, pp 1106–1118 

Landy
MS

Maloney
LT

Johnston
EB

Young
M


Measurement and modeling of depth cue combination: in defense of weak fusion
Vision Res
1995
35
389
412
10.1016/0042-6989(94)00176-M

7892735


Marotta
JJ

Kruyer
A

Goodale
MA


The role of head movements in the control of manual prehension
Exp Brain Res
1998
120
134
138
10.1007/s002210050386

9628412


Mather
G


The use of image blur as a depth cue
Perception
1997
26
1147
1158
10.1068/p261147

9509149


Milgram
P


A spectacle-mounted liquid-crystal tachistoscope
Behav Res Methods Instrum Comput
1987
19
449
456

Milgram P (1987) A spectacle-mounted liquid-crystal tachistoscope. Behav Res Methods Instrum Comput 19:449–456. doi:10.1068/p080125 

Muller
CPM

Brenner
E

Smeets
JBJ


Living up to optimal expectations
J Vis
2007
7
1
10
10.1167/7.3.2

Muller CPM, Brenner E, Smeets JBJ (2007) Living up to optimal expectations. J Vis 7:1–10. doi:10.1167/7.3.2 

Ono
H

Steinbach
MJ


Monocular stereopsis with and without head movement
Percept Psychophys
1990
48
179
187

2385492


Rogers
BJ

Collett
TS


The appearance of surfaces specified by motion parallax and binocular disparity
Q J Exp Psychol A
1989
41
697
717

2587795


Rogers
BJ

Graham
ME


Motion parallax as an independent cue for depth perception
Perception
1979
8
125
134
10.1068/p080125

471676


Rogers
BJ

Graham
ME


Similarities between motion parallax and stereopsis in human depth perception
Vision Res
1982
22
261
270
10.1016/0042-6989(82)90126-2

7101762


Rosas
P

Wagemans
J

Ernst
MO

Wichmann
FA


Texture and haptic cues in slant discrimination: reliability-based cue weighting without statistically optimal cue combination
J Opt Soc Am A Opt Image Sci Vis
2005
22
801
809
10.1364/JOSAA.22.000801

15898539


Rosenholtz
R

Malik
J


Surface orientation from texture: isotropy or homogeneity (or both)?
Vision Res
1997
37
2283
2293
10.1016/S0042-6989(96)00121-6

9578909


Ryan
C

Gillam
B


Cue conflict and stereoscopic surface slant about horizontal and vertical axes
Perception
1994
23
645
658
10.1068/p230645

7845758


Servos
P

Goodale
MA


Binocular vision and the on-line control of human prehension
Exp Brain Res
1994
98
119
127
10.1007/BF00229116

8013579


Stevens
KA


The information content of texture gradients
Biol Cybern
1981
42
95
105
10.1007/BF00336727

7326290


Ujike
H

Ono
H


Depth thresholds of motion parallax as a function of head movement velocity
Vision Res
2001
41
2835
2843
10.1016/S0042-6989(01)00164-X

11701179


Watt
SJ

Bradshaw
MF


The visual control of reaching and grasping: binocular disparity and motion parallax
J Exp Psychol Hum Percept Perform
2003
29
404
415
10.1037/0096-1523.29.2.404

12760624


Watt
SJ

Akeley
K

Ernst
MO

Banks
MS


Focus cues affect perceived depth
J Vis
2005
5
834
862
10.1167/5.10.7

16441189





