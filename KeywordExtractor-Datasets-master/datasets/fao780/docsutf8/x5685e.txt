<title>Manual 4. Manual of Methods for Fish Stock Assessment - Part 1. Fish Population Analysis</title>
<section>1</section>
SECTION 1. INTRODUCTION
In studying the state of the fish stocks and the effect of fishing on them, the fishery biologist should carry out his analysis in precise quantitative terms. To do this he must use mathematics, and to use mathematics the complexities of the real situation must be replaced by more or less simplified and abstract mathematical models. Such models may be used to represent both quantities of interest (abundance of the population, size of the individual fish), and the relation between these quantities.
In their simplest form, mathematical models are regularly used by biologists; for instance, it is commonplace to represent the size of a fish by the number of centimetres between the tip of its jaw and the end of its caudal fin. This model conceals many factors about the actual fish - whether it is fat or thin, or whether it is a cod or a tuna - but enables many analyses to be carried out - e.g. the construction of a length-frequency distribution of a sample of the fish population.
The value of a model may be judged by its simplicity and the closeness with which events or values predicted by the model fit the actual observation. A model cannot be considered as being either right or wrong, but as giving a satisfactory fit to the facts over a wide or narrow range of situations. A good model is one that is simple, but gives a good fit over a wide range.
The best test of a model is its usefulness in prediction; in this sense prediction covers not only the prediction of future events but also any values or events not considered in proposing the model. Thus a model describing the growth of cod in length may be proposed from the analysis of data of mean length at age; it will be a more useful model if, subject to the fitting of a minimum number of constants, it can be used to predict (estimate) the mean length at age of haddock, or any other species.
All the models described in this manual have proved to a greater or lesser extent to be useful models in that they have provided useful quantitative descriptions of events in various fisheries. Most have also been successful in making predictions, in the sense used above. A good example of the testing of a model by a successful prediction is the analysis of the Antarctic whale stocks. At the 1963 meeting of the International Whaling Commission there was considerable discussion on the quota, in terms of numbers of whales caught, to be set for the 1963/64 season. The Commission's Committee of Three Scientists had devised a model for the population of Antarctic fin whales, taking into account the probable rates of mortality and recruitment, etc. On the basis of this model the Committee had recommended that in order to rebuild the depleted stocks, not more than 5 000 fin whales should be killed, but that if whaling activities were continued at the 1962/63 rate about 14 000 fin
whales would be caught, equivalent, including catches of other whales, to some 8 500 Blue Whale Units (BWU). Members of the Commission were unwilling to make so large a reduction in the quota from that for the 1962/63 season (15 000 BWU), and therefore agreed on a quota of 10 000 BWU for 1963/64. This gave no effective restriction on whaling activities, and the catches were very close to the predicted values (13 870 fin whales, and a total of 8 429 BWU).
Such close agreement between observed and predicted values was partly a matter of luck, that is, certain assumptions made in constructing the model were quite closely fulfilled. In particular the model assumed that some factors influencing the catch, such as the weather and the skill of the gunners were, in the 1963/64 season, close to the average of previous seasons. These assumptions were nearly fulfilled, but a slight difference in weather or in the skill of a few gunners could have increased the difference between observed and predicted catches to perhaps three or four hundred animals. The closeness of the agreement did not prove that the model is correct, or that a slightly different model might not give a rather closer fit, but does prove that the model used can predict within useful limits the results of one pattern of whaling activity. Presumably the model could also predict the results of other patterns of activity, and in particular the result of a severe
restriction in catches for a period long enough to allow the stocks to rebuild. Therefore the model serves as a usable basis for managing the whale resources.
As in the whale example, most models include simplifying assumptions about the factors which are not of immediate interest (e.g. weather), usually stated, when stated explicitly, in the form "assuming the conditions are constant." This should not be taken to mean that the validity of the model depends on the constancy of these conditions, and that the model should not be used if conditions vary. Rather it means that for the purposes for which the model has been constructed, the variations caused by these conditions are not of primary interest, and will be ignored.
This manual is mainly concerned with studying the effect of fishing on the stocks and on the catches; it is, therefore, essentially concerned with the long-term effects. Also when predicting the catch from a given pattern of fishing the important question is often not the absolute amount of catch but the catch relative to that which would have been taken with some other pattern of fishing. Many fluctuations and variations are therefore irrelevant to the purposes of this manual. For instance, very often the average catch per trawl haul is taken as a measure of the abundance of the stock; the actual catch taken in one haul will depend on a large number of factors, e.g. the size of the trawler, the skill of the skipper, the precise ground, the season, the weather and the time of day, some of which may have a considerably greater influence on the catch of that particular haul than the overall abundance of the stock. Fish population dynamics is not however concerned with studying
or predicting the catch of one haul, but the average catch over a period, say a year. Most of these factors will have average annual values which are effectively constant from year to year, and thus can be ignored; only if these annual values vary, and particularly if they show a trend (e.g. an increase in the average size of trawler) may they have to be studied in detail.
When comparing the catches from two different patterns of fishing, e.g. trawling with large or small meshes in the cod-end, even year-to-year fluctuations can often be ignored. For instance, variations in recruitment may make big differences to the catch in any one year, but will not in general affect the conclusion that say with the present amount of fishing, the use of meshes of 120 mm in the cod-end will give sustained catches 5 percent larger than those taken when meshes of 110 mm are used.
Any model will eventually have to be replaced or modified, possibly merely by adding a little complexity to take into account further factors (e.g. weather conditions in the whale example above) to attain rather greater precision, or perhaps being replaced by a different model. In any case, the process of construction of a model, testing it, and modifying or replacing it is an essential part of the study and eventual understanding of the dynamics of fish populations, or indeed any subject of scientific study. The process of model construction is the complement of the collection of data, and in fact it is only by constructing and using models that it is possible to decide what data should be collected.
The basic model used in nearly the whole of this manual is one in which the stock considered is taken as being self contained, and the various factors causing the stock to change are considered separately. These factors are as follows:
Recruitment (see section 7) Growth of individuals (see section 3)
Deaths due to fishing; these will be determined by the fishing effort (see sections 4 and 5.3)
Deaths due to other causes (see section 5)
The changes with age in these factors and in the total weight of a year-class are illustrated in Figure 1.1. This shows the growth in weight of the individual; the decrease in the numbers of individuals (the full line shows the decrease in the absence of fishing, the broken line the decrease if fishing occurs after some age, t[c]); and the total weight of the stock. The last has a maximum at some intermediate age, the "critical" age of Ricker.
In the early sections each of these factors are considered separately, and the models are developed to describe each in quantitative terms. In the final sections the factors are combined to provide a quantitative model for the changes in total weight of the stock, and in catch, for various patterns of fishery. The modifications to the model which are necessary to take into account interactions between the various factors, e.g. that increased fishing will reduce the stock and therefore may affect the recruitment, are discussed briefly in section 11.
FIGURE 1.1. - Changes in numbers and weight of a year-class of fish during its life
<section>2</section>
SECTION 2. MATHEMATICS, STATISTICS AND SAMPLING
2.1 Mathematics
2.2 Statistics
2.3 Sampling
2.4 Exercises
2.1 Mathematics
2.1.1 Introduction
2.1.2 Functions
2.1.3 Powers and logarithms
2.1.4 Derivatives
2.1.5 Integrals
2.1.1 Introduction
In the analysis of a fishery and in stock assessment one is mainly interested in changes. They can be changes in the number of a stock with time, changes in weight of a fish with age, changes in yield with changes in the fishing effort, etc.
Changes with time are measured as rates, i.e. the change in the magnitude of the quantity (weight, etc.) considered divided by the period of time during which it occurred. Even if the time interval is not explicitly specified, unit time (e.g. one year) is usually to be inferred and thus the change is implicitly a rate.
Theoretical models have the advantage of permitting the analysis of the influence of some factors by studying the mathematical properties of the models. For mathematical simplicity in these models and elsewhere instantaneous rates are often used.
Instantaneous rates can be taken as the limit of the mean rates when the period of time, D t, tends to zero. Mathematically this is equivalent to the concept of the derivative.
The hypotheses to be made on the relationships between instantaneous rates and the variables can be expressed in the form of differential equations. The differential and integral calculus are important mathematical tools in the analysis of the dynamics of population and other systems. Some of these hypotheses lead to the exponential, logarithmic and power functions.
For the above-mentioned reasons a quick review of powers, exponential and log functions, as well as of differential and integral calculus, is important. Granville, Smith and Longley's Elements of the differential and integral calculus deals extensively with such matters.
2.1.2 Functions
Let x and y denote two variables. If to each value of x corresponds a value of y then we can say that y is a function of x or symbolically y =f (x). Graphically, if we plot the values of x on the abscissa (horizontal) axis and the corresponding values of y on the ordinate (vertical) axis, the curve joining the points, P (x, y), with abscissa x and ordinate y, is a graphical representation of the function y = f (x):
FIGURE 2.1.
Perhaps the simplest and one of the most used functions is the linear function y = a + bx where a and b are constants. Its graphical representation is a straight line with the intercept on the axis of y equal to a and the slope equal to b:
FIGURE 2.2.
When a = 0 then y = bx, which represents a straight line passing through the origin. This relationship states that y and x are directly proportional (Figure 2.3.1). For the special case b = 1, the equation y = x is the bisector of the positive quadrant (Figure 2.3.2).
FIGURE 2.3.1.
FIGURE 2.3.2.
The figure below shows the position of the straight line for different values of b
FIGURE 2.4.
Another way of writing the linear function is:
y - y[0] = b (x - x[0]) where (x[0], y[0]) is one point of the line.
This form is especially useful when we know two points of the line and we wish to formulate the equation. Thus, if one point is (x[0], y[0]) and the other is (x[1], y[1]) the line will pass through both if b satisfies the equation y[1] - y[0] = b (x[1] - x[0]), that is, b = (y[1] - y[0])/ (x[1] - x[0]). The equation can then be written immediately.
In a linear function the mean absolute rate of change of y with x is constant and equal to the slope. Thus the instantaneous absolute rate is also constant and its value is the slope b.
For any other function the mean absolute rate between two values x[0] and x[1], is the slope of the straight line passing through the points (x[0], y[0]) and (x[1], y[1])
FIGURE 2.5.
Another very useful function is the parabola, also called the second degree polynomial, y = a + bx + cx^2
FIGURE 2.6.
The equation can sometimes be written in the form: y = A (x - x[0]) (x - x[1]) where x[0] and x[1] are the intercepts on the x-axis and the sign of the constant A determines whether it is concave upward or downward.
FIGURE 2.7.1.
FIGURE 2.7.2.
FIGURE 2.7.3.
The exponential function y = a^x where a is a positive constant has the graphical representation shown in Figures 2.8.1 and 2.8.2.
FIGURE 2.8.1.
FIGURE 2.8.2.
An exponential function commonly used for its mathematical convenience is the one with a equal to the mathematical constant e.
Some curves have an asymptote, i.e. a straight line to which the curve approaches closer and closer as x becomes extremely large (or extremely small); more precisely they are tangents to the curve when x = ¥ (or - ¥). For example: y = ax with a < 1 (see Figure 2.8.1) has the asymptote y = 0; the curves y = 1 - e^-2x and y = 1 - e^-2x both have the asymptote y = 1, the second one approaching this asymptote rather more quickly.
FIGURE 2.9.
It is always possible to transform a mathematical function into a straight line relation by a suitable transformation of variables. This is often useful when fitting a theoretical, and possibly complicated curve to observed data; the fitting of a straight line, either graphically by eye, or by regression techniques is relatively simple. Fitting more complex curves, e.g. the exponential, is more difficult, either by eye or by calculation. It should be noted that the least square regression (or other fitted curve) which uses the arithmetic means of the transformed variables will probably not coincide with the arithmetic mean of the original variables, e.g. using the transformation w = log x, the arithmetic mean of the w's is the geometric mean of the x's.
As we will see later, the curve relating the number of fish of a year-class alive at time t can be expressed as N[t] = N[0]e^-Zt and can be transformed into the straight line y = a + bt, where a = log[e]N[0] and b = - Z, using the logarithmic transformation y = log[e]N.
FIGURE 2.10.1.
FIGURE 2.10.2.
2.1.3 Powers and logarithms
When the base is positive the power is positive, but when the base is negative the power is positive if the exponent is even and negative if the exponent is odd.
It is useful to consider the value of a power when the exponent n increases without limit.
If the base a is greater than 1 then a^n also increases without limit.
If the base a is equal to 1 then a^n is equal to 1 for all values of n.
If the base a is smaller than 1 (and positive) then a^n tends to 0.
Some useful rules for multiplying or dividing powers are:
- Powers with the same base
- Powers with the same exponent
To raise a power to an exponent, the base is raised to the product of the exponents:
(a^n)^m = a^nm
The function y = a^n can be considered in two ways depending on whether the base a, or the exponent n is considered as the variable of interest. In the form y = x^n (i.e. the base is the variable) it is called a power function; in the form y = a^x (i.e. the exponent is the variable) it is called an exponential function.
The inverse function of a power is a root and the inverse function of an exponential is a logarithmic function. Thus if y = a^x then x = log[a]y, or x is the logarithm of y to the base a.
When the base is the constant e, the logarithms are called natural or Napierian (or hyperbolic).
From the definition above one can see that the properties of the powers will imply corresponding properties of the logarithms, e.g.
log[a][ ](A · B) = log[a] A + log[a] B corresponds to the property a^x · a^y = a^x+y
log[a] (A^m) = m log[a] A corresponds to the property (a^x)^y == a^xy
Special relations can also be obtained, such as log[a] 1 = 0 and log[a] a = 1. The relation between the logs of a number on two different bases, a and b, is:
log[a] N = log[b] N · log[a] b
The bases most used for logs are the base 10 and the base e (e » 2.72), the former because 10 is the basis of the numerical system currently used and the latter because this results in the most simple form of several mathematical relationships. From the above relation the logarithm of a number to the base e can be obtained from the logarithm of the number on base 10 multiplied by log[e] 10 ~ 2.303. This is a useful expression if a table of natural logs is not available. One of the advantages of using the base 10 is that any number can be expressed as the product of a power of 10 and a number between 1 and 10, e.g. 283.5 = 10^2 × 2.835; 0.0053 = 10^-3 × 5.3. In this way the decimal log of any number will be the sum of the decimal log of a number between 1 and 10 (mantissa) plus the decimal log of a power of 10, that is, its exponent (characteristic).
From the above examples this would give log[10] 283.5 = 2 + log[10] 2.835 and log[10] 0.0053 = -3 + log[10] 5.3. The logarithms to base 10 of the numbers between 1 and 10 are given by tables.
Tables of natural logarithms are usually available over a wider range (perhaps from 0.1 to 100) but natural logarithms can be obtained by a similar method for any range from tables of the natural logarithms from 1 to 10. For instance,
log[e] 283.5 = 2 log[e] 10 + log[e] 2.835 = 2 × 2.303 + 1.042 = 5.648 and
log[e] 0.0053 = - 3 log[e] 10 + log[e] 5.3 = - 3 × 2.303 + 1.667 = - 5.242
2.1.4 Derivatives
As already stated, the concept of derivative is equivalent to the absolute instantaneous rate and this is the limit of the absolute mean rate during an interval when the length of the interval tends to zero.
FIGURE 2.11.1.
FIGURE 2.11.2.
Thus derivative, absolute instantaneous rate and slope of the tangent are equivalent concepts expressed from different viewpoints. Using this definition, we can calculate the derivative of a function. For instance, to determine the derivative of y = 3x^2 we can start by calculating the increment of y for a given increment of x. We obtain the value of the function at the point x + D x and subtract from the value of the function at the point x:
at x
y = 3^x^2
at x + D x
y + D y = 3 (x + D x)^2 = 6xD x + 3D x^2
then D y = 6xD x + 3D x^2
Derivatives can be arrived at easily if we obtain, in that way. some rules, e.g.
Derivative of a constant, c, is zero:
Derivative of a variable x with respect to itself is:
Derivative of the product of a constant c and a function u (x) is the product of the constant and the derivative of the function:
Derivative of a sum of two functions, u (x) and v (x), is the sum of their derivatives:
Derivative of a product of two functions, u (x) and v (x), is given by
Derivative of a power of a function u (x) is given by
Derivative of the quotient of two functions, u (x) and v (x), is given by
We can also obtain from further analysis the derivative of special functions often used in fisheries studies, such as
(e^x)' = e^x
(e^u)' = e^uu'
It is interesting to note that the derivative of the function e^x is e^x itself; it is this property of the exponential of base e which makes it so important on theoretical grounds.
The derivative of the function y = e^ax is y' = e^axa = ay; this means that the derivative, or the instantaneous rate, of y is proportional to y, a property very useful in many situations (e.g. studies of growth, mortality, etc.).
As an example of how we could apply these rules let us calculate the derivative of y = (3 + e^2^x) (1 - x^2).
Applying the rule for a product we can write
To calculate the derivative of the first factor we can apply the rule concerning the sum of two functions, then (3 + e^2^x)' = (3)' + (e^2^x)'. We thus see that (3)'= 0 and (e^2^x)' = e^2^x (2 x)' = e^2x · 2 and thus (3 + e^2^x)'= 2e^2^x. Calculating the derivative of the other factor: (1 - x^2)' = (1)' - (x^2)' = 0 - 2x = - 2x. Finally y' = 2e^2^x (1 - x^2) - 2x (3 + e^2^x).
The derivative of a function of x is, in general, another function of x. This function may also be differentiated to give another function of x. This last is called the second derivative of the original function. It is usually represented by the symbols y¢ ¢ or d^2y/dx^2 and could be interpreted as the absolute rate of the absolute rate, which in physics is called acceleration. Third, fourth, etc. derivatives can also be defined.
An application of the first derivative is the analysis of the change of a function and of the second derivative the analysis of the rate at which this change is itself changing. For the points where y' is positive, y is increasing, and where y' is negative, y is decreasing. If y' = 0, y is a stationary point. When y¢ ¢ is positive the slope of the curve is increasing and the graph of y is concave upward; when y¢ ¢ is negative the slope of the curve is decreasing and the curve is concave downward. If y¢ ¢ = 0, y is an inflection point (unless y' was also 0). From the sign of y¢ ¢ we can decide if the stationary points are maxima or minima.
FIGURE 2.12.
2.1.5 Integrals
In the last section we saw how, given a function, we could obtain its derivative. The reverse problem would be to obtain the function knowing its derivative. This operation is called integration and the function so obtained is called the integral. For instance, what is the integral of 3x^2? We have seen that the derivative of x^3 is 3x^2, thus an integral of 3x^2 could be x^3. But so also is x^3 + 4 or generally x^3 + C where C is any constant, since the derivative of a constant is zero. This means that the integration of a function does not produce a simple function but a family of functions defined by the additive, arbitrary constant C.
The rules of integration can easily be obtained from the rules of differentiation, as they are inverse operations. Thus
Useful expressions are
A technique very useful for integration is the change of variable. For instance to integrate e^4^x^-3 we can put v = 4x - 3 and dv == (4x - 3)' dx or dv = 4 dx. Then
If one knows a value of the integrated function it is possible to determine the corresponding value for the constant C. In general terms we can say that if y = F (x) + C is the integral of a function, and knowing that (x[0], y[0]) is a point of the integral curve then y[0] = F (x[0]) + C and C = y[0] - F (x[0]); thus y - y[0] = F (x) - F (x[0]) gives the curve which satisfies the conditions of the problem.
We have seen the integration as the inverse operation of differentiation. There is however another concept of integral. This concept can be easily understood through the calculus of areas, which is one of the most important applications of integrals. Let us, for instance, calculate the area under the curve y =f (x), the axis of abscisses and the ordinates at x = a and x = b.
FIGURE 2.13.
To calculate the definite integral we calculate as before the indefinite integral and subtract its value for x = b and for x = a, this is:
As an example let us calculate the area under the function y = 3x^2 + 5 between x = 2 and x = X.
(Note that when calculating geometrical areas the values of the function and of its integral must be taken as positive.)
Another very important application of integrals is in solving differential equations. A differential equation is an equation with derivatives or differentials, for instance, y' = 4 x - 1 or dy = (5 + 2x) dx.
Now each member can be integrated separately:
The same result could be presented in a slightly different way by, instead of the constant C, using arbitrary point (x[0], y[0]), thus
and
This last expression can be very useful when one is interested in pointing out some special point of the function.
2.2 Statistics
Fish population studies involve the measurement and analysis of many quantities - e.g. age compositions, and growth rates - few of which can be measured exactly, either because of their inherent variability or the difficulty of measurement. Statistics must therefore be used to some extent, if only in such a simple form as taking the mean of a set of values. Basic statistical methods are the same whatever the subject in which they are being applied, and are described in many textbooks. These notes will therefore only deal very briefly with the basic methods. Some applications, e.g. correlation and regression analysis will be dealt with later as they occur. In this section most attention will be paid to the problem of sampling fish populations. (Statistics is dealt with in more detail in another manual in this series, in which both the basic methods and special applications to fisheries are described.)
In statistics we are concerned not so much with any individual value, e.g. the size of any one particular fish on the fish market, but with the frequency with which the various values (e.g. size of fish) occur. Such frequency distributions may be represented graphically, either as histograms or frequency polygons. Much of the frequency distributions can be described by two quantities; the average value (or the position of the curve) and the spread. The most common measures for the average are the arithmetic mean (or simply mean), the median (or half way value) and the mode (or most frequent). Of these the mean has most advantages. The common measure of dispersion is the variance, which is the average of the square of the deviation from the mean; the square root of the variance is the standard deviation. Further discussions of these measures, together with methods of calculation etc. may be found in most textbooks, e.g. Yule and Kendall (1950), chapters 4, 5 and 6.
Tests of significance are another group of statistical tools of great use in fishery research, as in most other fields. While the explanation of the arithmetical steps involved in any particular test will be left to the appropriate section of the textbooks, e.g. Yule and Kendall (1950), chapter 21, it is worth emphasizing here the underlying basis of tests of significance. That is, we assume some null hypothesis, and on this basis calculate the probability of the observed values occurring. If this probability is sufficiently small (usually one in twenty, or one in a hundred) we reject the null hypothesis. For instance, using the t-test for the difference in the means of two samples, the null hypothesis is that the two samples come from the same population. If the probability of a value of t equal to or greater than that observed occurring is say 0.01, this means that if the two samples had come from the same population, an unlikely event (a one in a hundred chance) has taken
place and we therefore believe that the two samples did not come from the same population, i.e. they are statistically different. Such a test does not give any information on the probability of the two samples coming from different populations, or on the practical significance of the difference. For instance, two small and variable samples may differ by an amount which is not statistically significant, but which if real would be most important. Conversely, for two large and homogeneous samples a difference may be large enough to be statistically significant, but yet so small as to be negligible in practice.
2.3 Sampling
2.3.1 General
2.3.2 Sampling the landings
2.3.3 Sampling the population
(For further details see FAO. Manual of sampling and statistical methods for fisheries biology, by J.A. Gulland. Part 1. Sampling methods. Rome, 1966.)
2.3.1 General
Most of the quantities involved in fish population work cannot be obtained or measured throughout the whole population; e.g. it is virtually impossible to measure all fish caught, even less all the fish in the sea. A section, or sample, of the whole population is therefore examined for the attributes concerned, e.g. percentage of mature fish, or average size. On the assumption that this sample is representative of the whole population, an estimate may be made of the true value in the population. If the sampling system used is a good one, then the estimate obtained will differ little from the true value. The merits or otherwise of a sampling system can therefore be measured by two quantities relating to the estimates obtained (those measures refer not to any individual estimate, but to the set of estimates which might be obtained by repeated samples); firstly, the variance, which as defined above for any statistical distribution, is the measure of the scatter of the estimates
about their mean value; secondly, the bias, which is the extent to which the mean value of the set of possible estimates differs from the true value. (The term bias is also used for the processes leading to this difference.)
Because when a bias exists, it exists in all samples, tending to make the estimates constantly greater (or less) than the true value, it cannot be detected as a difference between repeated samples; thus in general bias is very difficult to detect, and hence eliminate, in subsequent analysis. A large variance, in contrast, appears at once in the differences between samples. Large bias is therefore even less desirable than large variance, in that it may cause what appear to be reliable and consistent data to give results that are consistent only in the extent to which they are wrong.
The basic feature of any good sampling system is a " random" sample. The aim of a random sample should be to ensure that all members of the collection of objects being sampled have the same chance of occurring in the sample. In practice this condition may be relaxed and the sampling be nonrandom so long as there is no relation between the chance of occurring in the sample, and the value of the attribute being measured. For instance, the first fish unloaded from a trawler onto the fish market is usually one of the last caught and will be placed near the edge of the array of fish and therefore have a better chance of appearing in the sample. If we are only concerned with sampling for the size of fish, this may not matter as there is little relation between size of fish and time of capture, but the sample would be a very bad one if we were concerned with the condition or freshness of the fish. The main damage done by nonrandom sampling is this introduction of bias (e.g. that
the sample taken above will be biased toward having too many fresh fish) though nonrandom sampling has other disadvantages, e.g. that many of the calculations used for estimating variance etc. are only valid for random samples. The first concern in taking a sample is therefore to ensure that no form of selection can occur that might cause a bias. Such selection may be very obvious and direct, e.g. the tendency to take the bigger fish from a pile, leaving the smaller until last, but may be much less obvious; e.g. in the East Anglian herring season it would seem convenient to take samples of herring from the first drifters arriving each morning. These tend to be from the nearer grounds, which in turn tend to have slightly different size and age of fish. Thus a nonrandomness in time of sampling may cause a bias in the estimate of average size or age of fish landed.
The practical difficulties in taking a truly random sample from a large and heterogeneous collection of objects are considerable. These difficulties may be overcome by dividing up the whole collection into smaller and more compact sections, within which a random sample may be taken fairly readily. Two such methods of sampling are stratified and two-stage sampling. In stratified sampling the whole collection of objects is divided into several sections, or strata, each of which is then sampled and analysed separately, e.g. landings at different ports may be taken as strata. This method is particularly useful