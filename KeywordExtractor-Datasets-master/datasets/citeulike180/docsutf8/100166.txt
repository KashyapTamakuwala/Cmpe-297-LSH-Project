Inferring Cellular Networks Using Probabilistic Graphical Models Nir Friedman, et al. Science 303, 799 (2004); DOI: 10.1126/science.1094068 The following resources related to this article are available online at www.sciencemag.org (this information is current as of May 7, 2008 ):
Updated information and services, including high-resolution figures, can be found in the online version of this article at: http://www.sciencemag.org/cgi/content/full/303/5659/799 Supporting Online Material can be found at: http://www.sciencemag.org/cgi/content/full/303/5659/799/DC1 A list of selected additional articles on the Science Web sites related to this article can be found at: http://www.sciencemag.org/cgi/content/full/303/5659/799#related-content This article cites 25 articles, 12 of which can be accessed for free: http://www.sciencemag.org/cgi/content/full/303/5659/799#otherarticles This article has been cited by 115 article(s) on the ISI Web of Science. This article has been cited by 26 articles hosted by HighWire Press; see: http://www.sciencemag.org/cgi/content/full/303/5659/799#otherarticles This article appears in the following subject collections: Computers, Mathematics http://www.sciencemag.org/cgi/collection/comp_math Information about obtaining reprints of this article or about obtaining permission to reproduce this article in whole or in part can be found at: http://www.sciencemag.org/about/permissions.dtl

Science (print ISSN 0036-8075; online ISSN 1095-9203) is published weekly, except the last week in December, by the American Association for the Advancement of Science, 1200 New York Avenue NW, Washington, DC 20005. Copyright 2004 by the American Association for the Advancement of Science; all rights reserved. The title Science is a registered trademark of AAAS.

Downloaded from www.sciencemag.org on May 7, 2008

MATHEMATICS IN BIOLOGY

SPECIAL SECTION

REVIEW

Inferring Cellular Networks Using Probabilistic Graphical Models
Nir Friedman
High-throughput genome-wide molecular assays, which probe cellular networks from different perspectives, have become central to molecular biology. Probabilistic graphical models are useful for extracting meaningful biological insights from the resulting data sets. These models provide a concise representation of complex cellular networks by composing simpler submodels. Procedures based on well-understood principles for inferring such models from data facilitate a model-based methodology for analysis and discovery. This methodology and its capabilities are illustrated by several recent applications to gene expression data. Research in molecular biology is undergoing a revolution. The availability of complete genome sequences facilitates the development of high-throughput assays that can probe cells at a genome-wide scale. Such assays measure molecular networks and their components at multiple levels. These include mRNA transcript quantities, protein-protein and protein-DNA interactions, chromatin structure, and protein quantities, localization, and modifications. These rich data illuminate the working of cellular processes from different perspectives and offer much promise for novel insights about these processes (1). The challenge for computational biology is to provide methodologies for transforming high-throughput heterogeneous data sets into
School of Computer Science and Engineering, Hebrew University, 91904 Jerusalem, Israel. E-mail: nir@ cs.huji.ac.il

biological insights about the underlying mechanisms. Although high-throughput assays provide a global picture, the details are often noisy, hence conclusions should be supported by several types of observations. Integration of data from assays that examine cellular systems from different viewpoints (for instance, gene expression and proteinprotein interactions) can lead to a more coherent reconstruction and reduce the effects of noise. To perform such an integration, however, we must understand the biological principles that couple the different measurements. In addition, the conclusions of the analysis should go beyond a mere description of the data and should provide new knowledge about the relevant biological entities and processes, ideally in the form of concrete, testable hypotheses. To answer this challenge, we need to build models of the biological system. A model is a simplifying abstraction. It gen-

erates predictions of system behavior under different conditions (as reflected by observations) and illuminates the roles of various system components in these behaviors. We focus on probabilistic models, which use stochasticity to account for measurement noise, variability in the biological system, and aspects of the system that are not captured by the model. In a model-based approach to data analysis, we start by defining the space of possible models that we are willing to consider. This modeling decision depends on the phenomena we wish to describe and how they are reflected by the observations. We then use a learning procedure to select the model that best fits the actual observations. (Such procedures are referred to by different names in different disciplines, including inference, estimation, reverse engineering, and system identification.) Finally, we use the learned model to reason about the data, make predictions, and glean insights and hypotheses. An important aspect of model-based approaches is the shift from a procedural methodology to a declarative one. In a procedural method, we focus on the sequence of steps from the data to the conclusions. For example, when relating transcription factor binding sites in the promoter regions

www.sciencemag.org SCIENCE VOL 303 6 FEBRUARY 2004

799

Downloaded from www.sciencemag.org on May 7, 2008

41. S. Nee, Philos. Trans. R. Soc. Lond. B Biol. Sci. 355, 1607 (2000). 42. R. M. May, Stability and Complexity in Model Ecosystems (Princeton Univ. Press, Princeton, NJ, 1973). 43. B. Sinervo, C. M. Lively, Nature 380, 240 (1996). 44. B. Kerr, M. A. Riley, M. W. Feldman, B. J. M. Bohannan, Nature 418, 171 (2002). 45. S. A. Frank, in Foundations of Social Evolution, J. R. Krebs, T. H. Clutton-Brock, Eds. (Princeton Univ. Press, Princeton, NJ, 1998). 46. E. Sober, D. S. Wilson, Unto Others: The Evolution and Psychology of Unselfish Behavior (Harvard Univ. Press, Cambridge, MA, 1998). 47. M. A. Nowak, R. M. May, Nature 359, 826 (1992). 48. A. Sasaki, W. D. Hamilton, F. Ubeda, Proc. R. Soc. London Ser. B 269, 761 (2002). 49. P. D. Taylor, L. Jonker, Math. Biosci. 40, 145 (1978). 50. J. Hofbauer, K. Sigmund, Evolutionary Games and Population Dynamics (Cambridge Univ. Press, Cambridge, 1998). 51. J. W. Weibull, Evolutionary Game Theory (MIT Press, Cambridge, MA, 1996). 52. C. Hauert, S. De Monte, J. Hofbauer, K. Sigmund, Science 296, 1129 (2002). 53. T. Vincent, B. Brown, Evolutionary Game Theory, Natural Selection, and Darwinian Dynamics (Cambridge Univ. Press, Cambridge, 2003).

54. D. Fudenberg, K. Levine, The Theory of Learning in Games (MIT Press, Cambridge, MA, 1998) 55. R. Ferriere, R. Michod, Am. Nat. 147, 692 (1996). 56. U. Dieckmann, R. Law, J. A. J. Metz, Eds., The Geometry of Ecological Interactions: Simplifying Spatial Complexity (Cambridge Univ. Press, Cambridge, 2000). 57. R. Durrett, SIAM (Soc. Ind. Appl. Math.) Review 41, 677 (1999). 58. R. Cressman, Evolutionary Dynamics and Extensive Form Games (MIT Press, Cambridge, MA, 2003). 59. J. A. J. Metz, R. M. Nisbet, S. A. H. Geritz, Trends Ecol. Evol. 7, 198 (1992). 60. S. D. Mylius, O. J. Diekmann, J. Theor. Biol. 211, 297 (2001). 61. R. Boyd, J. Lorberbaum, Nature 327, 58 (1987). 62. M. A. Nowak, K. Sigmund, Acta Appl. Math. 20, 247 (1990). 63. J. Hofbauer, K. Sigmund, Appl. Math. Lett. 3, 75 (1990). 64. U. Dieckmann, R. Law, J. Math. Biol. 34, 579 (1996). 65. A. P. Hendry, J. K. Wenburg, P. Bentzen, E. C. Volk, T. P. Quinn, Science 290, 516 (2000). 66. U. Dieckmann, P. Marrow, R. Law, J. Theor. Biol. 176, 91 (1995). 67. I. Eshel, J. Theor. Biol. 103, 99 (1983). 68. F. B. Christiansen, Am. Nat. 138, 37 (1991). 69. P. D. Taylor, Theor. Pop. Biol. 36, 125 (1989).

70. M. A. Nowak, J. Theor. Biol. 142, 237 (1990). 71. J. A. J. Metz, S. A. Geritz, G. Meszena, F. J. A. Jacobs, J. S. van Heerwarden, in Stochastic and Spatial Structures of Dynamical Systems, S. J. Van Strien, S. M. Verduyn Lunel, Eds. [Koninklijke Nederlandse Academie van Wetenschappen (KNAW), Amsterdam, 1996], pp. 183­231. 72. S. A. Geritz, J. A. J. Metz, E. Kisdi, G. Meszena, Phys. Rev. Lett. 78, 2024 (1997). 73. K. Parvinen, Bull. Math. Biol. 61, 531 (1999). 74. I. Eshel, J. Math. Biol. 34, 485 (1996). 75. R. Burger, Am. Nat. 160, 661 (2002). ¨ 76. P. Hammerstein, J. Math. Biol. 34, 511 (1996). 77. M. Slatkin, Genetics 93, 755 (1979). 78. U. Dieckmann, M. Doebeli, Nature 400, 354 (1999). 79. C. Matessi, A. Gimelfarb, S. Gavrilets, Select. Mol. Genes Memes 2, 41 (2001). 80. M. Gyllenberg, K. Parvinen, U. Dieckmann, J. Math. Biol. 45, 79 ­105 (2002). 81. L. Van Valen, Evol. Theory 1, 1 (1973). 82. For an interactive Web page, see www.univie.ac.at/ virtuallabs. 83. K. M. Page, M. A. Nowak, J. Theor. Biol. 219, 93 (2002). 84. Support from the Austrian Science Fund WK 10008, the Packard Foundation, and J. Epstein is gratefully acknowledged.

MATHEMATICS IN BIOLOGY

SPECIAL SECTION

of genes to their expression profiles, we can start by finding clusters of coexpressed genes and then search for overrepresented elements in the promoters of the genes in each cluster (2). Alternatively, we can group genes with similar binding sites in their promoter regions, and then test whether they are coexpressed (3). In contrast, in a declarative approach we start by designing a model that encompasses both gene expression and binding sites. As explained below, such a model explicitly describes the assumptions we make about the relations between the two types of data. By doing so, we clarify what kinds of predictions we can perform with each model, after we learn its parameters from the data and how these parameters relate to the biological phenomena we are attempting to capture. Next, we apply well-understood principles such as maximum likelihood estimation to fit the model to the data. This can be done using a general-purpose strategy (such as Expectation Maximization, gradient ascent, or Gibbs sampling) in the context of the particular model. By treating different data sets within one model, the learning procedure can combine evidence from multiple data sets and reach more robust conclusions. The model-based approach is widely used in biological sequence analysis (4 ), for which there is a range of established sequence models such as Hidden Markov Models. For cellular networks, the structure of the underlying processes that generate the observed measurements is not fully characterized, and the question of which mechanism to model--and at what granularity--is open-ended and depends on the biological question we are attempting to answer. In this review, I examine the use of a class of mathematical models known as probabilistic graphical models (5, 6 ) for model-based analysis of cellular networks. These models were developed in the fields of machine learning and statistics for modeling complex systems with multiple interacting entities. They are closely related to probabilistic sequence models but are not restricted to sequential observations. Probabilistic graphical models are suitable for this task for several reasons. They provide a concise language for describing probability distributions over the observations. The computational procedures for reasoning in graphical models are derived from basic principles of probability theory. In addition, the literature on graphical models provides approaches to learning from data that are derived from basic well-understood principles in statistics. These approaches allow the use of observations to "fill in" many model details. Furthermore, they provide principles for combining multiple local models into a joint global model. This provides flexibility when construct-

ing models for novel data sets or experimental designs. Using graphical models, one can construct simple submodels and then combine them for the full model. Finally, the declarative nature of graphical models provides an advantage when we need to extend the model to account for additional aspects of the system or new observations. My emphasis is on the modeling choices and how they facilitate different analysis tasks. For each of these models, we also need to apply inference and learning procedures. In some cases, we can adopt generic strategies. In others, finding computationally efficient algorithms is a major challenge, and the details of the algorithms (not discussed here) greatly affect the results.

Probabilistic Graphical Models
When modeling a biological system, we are interested in entities that are involved in the system under study (e.g., genes) and their different attributes (e.g., expression level). In a probabilistic model, we treat each of these attributes as a random variable (7 ). Random variables include observed attributes, such as the expression level of a particular gene in a particular experiment, as well as hidden attributes that are assumed by the model, such as the cluster assignment of a particular gene. A model embodies the description of the joint probability distribution of all the random variables of interest. Probabilistic graphical models represent multivariate joint probability distributions via a product of terms, each of which involves only a few variables. The structure of the product is represented by a graph that relates variables that appear in a common term. This graph specifies the product form of the distribution and also provides tools for reasoning about the properties entailed by the product (5). For a sparse graph, the representation is compact and in many cases allows effective inference and learning. In Bayesian Networks, the joint distribution over a set X {X1, ..., Xn} of random variables is represented as a product of conditional probabilities. A Bayesian network associates with each variable Xi a conditional probability P(Xi Ui), where Ui X is the set of variables that are called the parents of Xi. Intuitively, the values of the parents directly influence the choice of value for Xi. The resulting product is of the form P(X 1, ..., X n )
i

P(X 1, ..., X n )

1 Z

j j

[C j ]

(2)

P(X i U i )

(1)

The graphical representation is given by a directed graph where we put edges from Xi's parents to Xi (Fig. 1, A to C). If the graph is acyclic, the product decomposition of Eq. 1 is guaranteed to be a coherent probability distribution.

where j[Cj] is the jth potential over the X, and Z is a normalizing variables Cj constant that ensures that the total probability mass is 1 (Fig. 1, D to F). A canonical example of an undirected model is an Ising model, where each random variable represents the orientation of an element (e.g., magnetic particle) and the potential between pairs of elements captures the compatibility of two elements. The joint probability is determined by the overall compatibility of each assignment of values according to all the potentials. Another related class of models are Chain Graphs, which involve a product of conditional probabilities and potentials. In many domains there is additional structure, beyond the product form, that can be exploited for concise representation (8). Below, we discuss one such class of models that captures additional structure. A crucial question for the tasks we examine here is inferring, or "learning," models from observations (6, 8). The general aim is to learn a model that is as close as possible to the underlying distribution from which the observations were made. We distinguish two main tasks: parameter estimation and model selection. In parameter estimation, we learn the parameters of the conditional probabilities for a given model structure. This task is often addressed as a

800

6 FEBRUARY 2004 VOL 303 SCIENCE www.sciencemag.org

Downloaded from www.sciencemag.org on May 7, 2008

Bayesian networks appear naturally in several domains in biology. In pedigree analysis, for example, the joint distribution of genotypes in a pedigree is a product of conditional probabilities of the genotype of each individual given the genotypes of its two biological parents. In phylogenetic models, the probability over all possible sequences during evolution is the product of the conditional probability of each sequence given its latest ancestral sequence in the phylogeny. To specify a model completely, we need to describe the conditional probability associated with each variable. In general, any statistical regression model may be used. For example, we can consider models where each P(Xi Ui) is a linear regression of Xi on Ui. Alternatively, we can use decision trees to represent the probability of a discrete variable Xi given the values of its parents. The choice of a specific parametric representation of the conditional probabilities is often dictated by our knowledge or assumptions about the domain. Another class of models are Markov Networks, which represent a joint distribution as a product of potentials. Each potential captures the interactions among a (small) set of variables and specifies the "desirability" of joint value assignments to these variables. This results in a product of the form

MATHEMATICS IN BIOLOGY

SPECIAL SECTION

Bayesian network once we are given the set of genes and arrays. The model just described can achieve high likelihood if the cluster and gene assignment partitions the original measurements into blocks with approximately uniform expression within each block (11). We can learn such a partition by using an Expectation Maximization procedure that iterates between an E-step, which uses current parameters to find the probabilistic cluster assignment of genes and arrays, and an M-step, which reestimates the distribution within each gene/ array cluster combination on the basis of this assignment. This basic model can be extended to capture additional insight about the biological mechanisms. We consider one example here. It From Clustering to is common to assume that coexRegulation pression of genes reflects coregulaWe now consider a graphical modtion. A key regulation mechanism el for gene expression data and involves binding of transcription then examine how to extend it to factors to promoter regions of the modeling of cis-regulatory elegenes. Thus, we aim to identify the ments. The main sources of hightranscription factor binding sites in throughput data on the behavior of the promoter region of genes that cellular networks are gene exprescan explain observed coexpression. sion profiles, obtained using DNA To do this, we extend the model to microarrays. A typical data set reinclude observations about promotports the expression level of thouer sequences. A straightforward apsands of genes as measured by sevproach is to maintain the clustering eral dozens or hundreds of arrays. model, where genes in the same clusWe treat these as observations of ter have similar expression patterns, the values of random variables and in addition associate each cluster Xg,a, where g is an index over with the transcription factors that reggenes and a is an index over arrays. ulate it. Although such a description A fairly simple modeling asoversimplifies the biological mechasumption is that genes can be parnism, it can capture the first-order titioned into clusters of coexsignal while ignoring many differpressed genes, and that the genes ences between the expression and in each cluster have a typical exregulation of specific genes. pression level in each array. We There are several ways to might also assume that arrays are Fig. 1. (A) A Bayesian network over five binary random variables. Vertices translate this intuition into a partitioned into array clusters, are labeled with random variable names (A to E); edges correspond to mathematical model. One apdirect dependencies. (B) The product form specified by this Bayesian which capture relevant biological network structure. A full specification of the joint distribution for these proach is to annotate promoters context, and that the expression random variables requires 31 parameters; this product form requires 10 with characterized binding sites, of a gene is roughly the same in parameters. (C) An example of one conditional distribution in the product and then use these as new atarrays that belong to the same form that specifies P(C A,B). (D) A Markov network over the same five tributes of the gene entity. The array cluster. We can pose this variables. (E) A product form that induces this Markov network structure. random binary variable Rg, j demodel by adding random vari- This is a product of four potential functions, each a function of a subset notes whether gene g has a bindof the variables. (F) One potential in this product form. ing site of transcription factor j. ables, so that GeneClusterg denotes the cluster assignment of Then, we can design a model gene g, and ArrayClustera denotes the cluster where the cluster assignment of each gene scheme or template is shared by all entities assignment of array a. The underlying asdirectly influences the associated binding of the same type. For example, the condisumption is that the expression of gene g in sites and expression attributes (12, 13). tional probability of P(Xg,a GeneClusterg, ArrayCluster a ) is similar for different array a depends on the value of GeneClusterg Alternatively, we can attempt to maxichoices of g and a. By capturing such and ArrayClustera. This model assumes that mize the likelihood of gene expression proregularities, we can provide a more concise all measurements that correspond to a particfiles given the promoter region content. representation of the model. One such repular gene cluster­array cluster pair are govAgain, we introduce binding site attributes to resentation is the language of relational erned by the same conditional distribution. the gene entity, but now we assume that the Bayesian networks (10, 11). Figure 2B We can describe such a model as a gene cluster depends on these attributes (14, shows a template model for the clustering Bayesian network. The structure of the 15). Such a model focuses on binding sites problem, from which we can generate the Bayesian network is regular, in the sense that predict expression and does not attempt www.sciencemag.org SCIENCE VOL 303 6 FEBRUARY 2004

maximum likelihood problem. In model selection, we select among different model structures to find one that best reflects the dependencies in the domain. This task is often addressed as a discrete optimization problem where we try to maximize a score that measures how well each candidate structure matches the observed data (22). Once we specify or learn a model that describes a joint distribution, we can use it to compute the likelihood of our observations and make predictions about the value of unobserved random variables given these observations. There is a wide choice of exact and approximate methods for answering such queries. These exploit, when possible, the structure of the product form for efficient computation (5, 9).

that each expression attribute Xg,a has parents GeneClusterg and ArrayClustera. The actual network structure depends on the number of genes and arrays in the data set (see Fig. 2A for a small example). The description by a Bayesian network, however, does not explicitly represent two important aspects. First, the random variables denote attributes of different entities, such as genes and arrays. Second, a general

801

Downloaded from www.sciencemag.org on May 7, 2008

MATHEMATICS IN BIOLOGY

SPECIAL SECTION

to account for the occurrences of other binding sites, which might be relevant under conditions that are not represented in the expres-

sion data. We can augment this model by modeling the probability of a binding site given the actual promoter sequence. We in-

Fig. 2. (A) A Bayesian network for the clustering problem in a simple data set with three genes and two arrays. The random variable Xg,a denotes the spot that measures expression of gene g in array a, GCg denotes the cluster of gene g, and ACa denotes the array cluster of array a. (B) A relational Bayesian network template for the basic clustering model. Boxes delimit entity types; dotted lines correspond to relations between entities (e.g., the relation between a spot entity and a gene entity denotes that the spot measures the expression of the particular gene). Each spot entity has a single attribute that measures an expression level and is associated with a gene entity and an array entity. Each gene entity is associated with a gene cluster, and each array entity with an array cluster. (C) Representation of the conditional distribution of expression levels given the clusters of the corresponding gene and array. Each combination of values of the respective gene-cluster and array-cluster variables is associated with parameters of a Gaussian distribution (mean and standard deviation ). (D) A template model that also includes promoter sequences. Each gene entity is associated with a promoter entity that has a sequence attribute that reports the DNA sequence of the promoter. The gene entity now has new attributes, where Rj indicates whether the gene is regulated by the jth transcription factor. This indicator depends on the promoter sequence. The cluster of the gene depends on the combination of these indicators.

troduce new entities that denote the promoter regions, and model Rg,j as depending on the promoter sequence Seqg (Fig. 2D). The parameters of this conditional probability characterize the specific motif recognized by the transcription factor. This extension allows us to learn the characterization of the binding site while learning how its presence influences gene expression. A crucial detail in building such a model is the representation of the conditional distributions associated with GeneClusterg. This distribution describes how the existence of binding sites in the promoter region determines (or predicts) what cluster the gene belongs to. The conditional probabilities explored so far involve fairly generic representation of decision trees (14) or additive votes (15). Both representations manage to reconstruct some aspects of yeast transcriptional circuits. However, it is not clear whether either one matches the underlying logic in biological regulation. Learning in this type of model combines similarity of genes in terms of expression and in terms of their promoters. In training the model, there are steps where we find new binding sites that explain assignments of genes to clusters, steps that reassign genes to new clusters on the basis of both their expression profile and their promoter region, and steps that reestimate the distributions of expression within each cluster. Thus, learning involves information flow between the two types of data and allows the combination of weak evidence from both sources. This information is channeled through the gene cluster variables. Thus, to achieve high likelihood, the gene cluster variables must represent clusters of genes with both coherent expression profiles and similar promoters. At the same time, the learning procedure must identify the binding site motifs that are most predictive of these cluster assignments. Segal et al. (15) applied such a model to two data sets of yeast gene expression profiles. One involved 800 genes in 77 arrays of different yeast cell cycle stages (16 ); the other involved 1000 genes in 173 arrays of yeast under environmental stress conditions (17). They showed that, without using prior knowledge, their procedure identified several dozen binding site motifs. More than half of these corresponded to motifs that have been characterized in the literature; the resulting gene clusters corresponded to known biological processes and function annotations. This correspondence is significantly more pronounced than for standard clusters learned from gene expression alone. In addition, their model suggests a specific cis-regulatory circuit that in many cases corresponds to prior knowledge about regulation in yeast. The clustering model can be extended to involve other types of mechanisms and ob-

802

6 FEBRUARY 2004 VOL 303 SCIENCE www.sciencemag.org

Downloaded from www.sciencemag.org on May 7, 2008

MATHEMATICS IN BIOLOGY

SPECIAL SECTION

Reconstruction of Regulatory Networks
A key challenge in gene expression analysis is the reconstruction of regulatory networks. A simple thought experiment suggests the following formulation. If the expression of gene A is regulated by proteins B and C, then A's expression level is a function of the joint activity levels of B and C. Because of variability in underlying biology and measurement noise, we treat the expression of A as a stochastic function of its regulators. This suggests a Bayesian network where the expression level of each gene depends on the activity levels of its regulators. In most current biological data sets, however, we do not have access to measurements of protein activity levels. Hence, we resort to using expression levels of genes as a proxy for the activity level of the proteins they encode. This is a problematic assumption, as there are numerous examples where an activation or silencing of a regulator is carried out by posttranscriptional protein modifications. With this caveat in mind, we set out to find a Bayesian network that relates the expression level of a gene to those of its regulators (21). That is, we search for a Bayesian network that specifies for each gene g a set of regulators, so that in each array Xg,a depends on the expression level of the regulators in that array. We then use tools for structure learning in Bayesian networks (22, 23) to determine the network architecture. This involves considering different network structures and evaluating the likelihood that they have generated the observations. This general outline faces two main challenges. The first challenge involves statistical robustness. Building a network that involves thousands of genes from several dozen examples of their joint expression levels (arrays) is extremely problematic. Such a small number of examples does not suffice to distinguish

www.sciencemag.org SCIENCE VOL 303 6 FEBRUARY 2004

803

Downloaded from www.sciencemag.org on May 7, 2008

servations. For example, we can assume that active transcription factor binding sites should correspond to observations of transcription factor location data (18). We can extend the model to view these observations as a noisy sensor (14). Another orthogonal extension can incorporate protein-protein interactions. For example, a pair of interacting proteins are more likely to belong to the same coregulated cluster (because they might act together). To capture this, we can assign a Markov network pairwise potential that prefers coordinated cluster assignments for pairs of interacting proteins (19). This model can combine annotation of proteins (e.g., cluster assignment) with protein-protein interaction data. This pairwise interaction model can be applied to other types of protein annotations. Deng et al. (20) recently used a similar model for predicting functional annotations of proteins.

between true correlations and spurious ones. There are several strategies to deal with this challenge. Methods such as the bootstrap can identify significant network features that are robust to perturbations of the observations (21, 24 ). Another approach is to use prior knowledge about biological principles to restrict the set of network structures we are willing to consider (25, 26 ). This reduces the number of competing "false" structures and increases robustness. Alternatively, we can restrict ourselves to evaluating a much smaller set of structures on the basis of prior biological knowledge about specific genes (27). Finally, we can rely on biological principles for restricting the stochastic function of a gene, given its regulators, to be of a particular form (26­29). The second and more difficult challenge is the biological interpretability of the results. Can we really distinguish regulation from coexpression? Do these methods discover direct or indirect regulation? How do unobserved posttranscriptional events affect the conclusions? Whereas our ultimate goal is to identify the direct regulation of targets by transcription factors, experience shows that the methods also find many other indirect relations. As a specific example, we applied (24 ) t