{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSXjT-i9sEvE"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "def fetch_all_data():\n",
    "    data_list=[]\n",
    "    \n",
    "    mongoclinet= MongoClient(\"mongodb+srv://Kashyap:Kt1234@cmpe-297-project.hyaud2z.mongodb.net/?retryWrites=true&w=majority\")\n",
    "    mydb = mongoclinet[\"Cmpe-297-database\"]\n",
    "\n",
    "    ## Collection\n",
    "    mycol = mydb[\"Data\"]\n",
    "    cursor = mycol.find({})\n",
    "    for document in cursor:\n",
    "        data_list.append([document[\"document_data\"],document[\"document_key\"]])\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIIC2TTqsEvL"
   },
   "outputs": [],
   "source": [
    "data = fetch_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AHnAfL2sEvM"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from random import randint as rint\n",
    "def preProcessData(data,fg = False):\n",
    "    ndata = []\n",
    "    ln = 0\n",
    "    for doc in data:\n",
    "        if fg:\n",
    "            doc,_ = doc\n",
    "        doc = doc.lower()\n",
    "        doc = doc.replace('\\n',\" \")\n",
    "        \n",
    "        doc = re.sub('[\\W_]+', ' ', doc)\n",
    "        if fg:\n",
    "          ndata.append(doc.split()[:250] + [doc[rint(0,len(doc)-1)] for _ in range(250)] + doc.split()[-250:])\n",
    "        else:\n",
    "          ndata.append(doc.split())      \n",
    "    return ndata\n",
    "def shingleText(text,shingleSize = 3):\n",
    "    shingles = []\n",
    "    for i in range(len(text)-shingleSize+1):\n",
    "        if i + shingleSize < len(text):\n",
    "            shingles.append(\" \".join(text[i:i+shingleSize]))\n",
    "    return shingles\n",
    "\n",
    "def convertToFreq(data):\n",
    "    wrds,iwcnt = dict(),1\n",
    "    shingles_docs = []\n",
    "    rfeatures = list()\n",
    "    for doc in data:\n",
    "        shingles = shingleText(doc)\n",
    "        #print(shingles)\n",
    "        for wrd in shingles:\n",
    "            if wrds.get(wrd,0) == 0:\n",
    "                wrds[wrd] = iwcnt\n",
    "                iwcnt += 1\n",
    "        shingles_docs.append(shingles)\n",
    "    \n",
    "    ndocs = []\n",
    "    for sdoc in shingles_docs:\n",
    "        tli = dict()\n",
    "        for swrd in sdoc:\n",
    "            tli[wrds[swrd]-1] =  tli.get(wrds[swrd]-1,0) + 1\n",
    "        if len(sdoc):\n",
    "            rfeatures.append(wrds[sdoc[0]]-1)\n",
    "            for _ in range(2):\n",
    "                rfeatures.append(wrds[sdoc[rint(0,len(sdoc)-1)]]-1)\n",
    "        ndocs.append(tli)\n",
    "    del shingles_docs\n",
    "    return ndocs,wrds,set(rfeatures)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTTnmX-_sei3"
   },
   "outputs": [],
   "source": [
    "pdata = preProcessData(data,True)\n",
    "fdata,wrds,red_features = convertToFreq(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pe9s-g7Me8Am",
    "outputId": "9ca10b4f-b721-4874-f317-daae83ac9eed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31480, 3229923)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(red_features),len(wrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRJ6w24iyUlp"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "class LSH:\n",
    "    def __init__(self,data,features,nfunc,ntabs,nfeatures,red_features,rfeature_size = 10000):\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.rdata = []\n",
    "        self.rfeature_size = rfeature_size\n",
    "        self.red_features = red_features\n",
    "        self.rfeatures = None\n",
    "        self.nfeatures = nfeatures\n",
    "        self.nfunc = nfunc\n",
    "        self.ntabs = ntabs\n",
    "        \n",
    "        self.hsh_fn_tb = [{} for _ in range(ntabs)]\n",
    "        self.tables = [dict() for _ in range(ntabs)]\n",
    "        self.randFeatures()\n",
    "        self.hashData()\n",
    "    def encodeQueryData(self,query_data):\n",
    "        ndata = []\n",
    "\n",
    "        qpre_data = [shingleText(row) for row in preProcessData(query_data)]\n",
    "        queries = []\n",
    "        for sdoc in qpre_data:\n",
    "            tli = dict()\n",
    "            for swrd in sdoc:\n",
    "                if wrds.get(swrd,0):\n",
    "                    tli[wrds[swrd]-1] = tli.get(wrds[swrd]-1,0) + 1\n",
    "            queries.append(tli)\n",
    "        for row in queries:\n",
    "            trow = [0]*self.rfeature_size\n",
    "            for i,id in enumerate(self.rfeatures):\n",
    "                trow[i] += row.get(id,0)\n",
    "            ndata.append(np.asarray(trow))\n",
    "        return np.asarray(ndata)\n",
    "\n",
    "    def randFeatures(self):\n",
    "        self.rfeatures = np.random.randint(low = 0,high = len(self.features)-1,size = self.rfeature_size)\n",
    "        self.rfeatures = self.rfeatures.tolist()\n",
    "        self.rfeatures.extend(self.red_features)\n",
    "        self.rfeatures = np.asarray(list(set(self.rfeatures)))\n",
    "        self.rfeature_size = self.rfeatures.size\n",
    "\n",
    "        for row in self.data:\n",
    "            trow = [0]* self.rfeature_size\n",
    "            for i,id in enumerate(self.rfeatures):\n",
    "                trow[i] += row.get(id,0)\n",
    "            self.rdata.append(np.asarray(trow))\n",
    "        self.rdata = np.asarray(self.rdata)\n",
    "        return None\n",
    "    def getHash(self,x,table_id = 0, func_id = 0):\n",
    "        hash_func = self.hsh_fn_tb[table_id]\n",
    "        num_feature = len(x)\n",
    "        if func_id not in hash_func:\n",
    "            r = np.random.randn(num_feature)\n",
    "            r = r / norm(r)\n",
    "            hash_func[func_id] = r\n",
    "        r = hash_func[func_id]\n",
    "        hrdot = x.dot(r.T)\n",
    "        return 1 if hrdot > 0 else 0\n",
    "\n",
    "    def getSignature(self,x,table_id = 0):\n",
    "        hash_key = ''\n",
    "        for func_id in range(self.nfunc):\n",
    "            hval = self.getHash(x,table_id,func_id)\n",
    "            hash_key += '%d' % hval\n",
    "        return hash_key\n",
    "    def hashData(self):\n",
    "        for i in range(self.rdata.shape[0]):\n",
    "            crow = self.rdata[i,:]\n",
    "            for table_id in range(self.ntabs):\n",
    "                table = self.tables[table_id]\n",
    "                hash_key = self.getSignature(crow,table_id)\n",
    "                table.setdefault(hash_key,set()).add(i)\n",
    "        return None\n",
    "    @staticmethod\n",
    "    def proximity(x,y):\n",
    "        return x.dot(y.T)/(norm(x)*norm(y))\n",
    "\n",
    "    def search(self, qdata, k = 5):\n",
    "        candidates = set()\n",
    "        for table_id in range(self.ntabs):\n",
    "            table = self.tables[table_id]\n",
    "            hash_key = self.getSignature(qdata,table_id)\n",
    "            print(table.get(hash_key,set()),table.keys(),hash_key)\n",
    "            candidates = candidates.union(table.get(hash_key,set()))\n",
    "        similarity = [(i,self.proximity(self.rdata[i],qdata)) for i in candidates]\n",
    "        self.nsims += len(similarity)\n",
    "        similarity.sort(key = lambda x:x[1],reverse = True)\n",
    "        k = min(k,len(similarity))\n",
    "        return similarity[:k]\n",
    "    \n",
    "\n",
    "    def findSimDocs(self, qdata, k = 5):\n",
    "        num_q = qdata.shape[0]\n",
    "        #tmp_qdt = []\n",
    "        #for row in qdata:\n",
    "        #    tr = [0]*self.nfeatures\n",
    "        #    for i,id in enumerate(self.rfeatures):\n",
    "        #        tr[i] += row.get(id,0)\n",
    "        #    tmp_qdt.append(np.asarray(tr))\n",
    "        #qdata = np.asarray(tmp_qdt)\n",
    "        \n",
    "        nbrs = np.full((num_q,k),-1,dtype=np.double)\n",
    "        nvals = np.zeros((num_q,k),dtype=np.double)\n",
    "        self.nsims = 0\n",
    "        for i in range(num_q):\n",
    "            sims = self.search(qdata[i,:],k = k)\n",
    "            nk = len(sims)\n",
    "            if not nk:\n",
    "                continue\n",
    "            nbr,sim = zip(*sims)\n",
    "            nbrs[i,:nk] = nbr\n",
    "            nvals[i,:nk] = sim\n",
    "        return nbrs,nvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_sOah8oC4bb"
   },
   "outputs": [],
   "source": [
    "l1 = LSH(fdata,wrds,30,10,10000,red_features=red_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrmD8LOWC8vY"
   },
   "outputs": [],
   "source": [
    "def naiveSimDocs(data,qd,wrds, k =5):\n",
    "    sim_func = lambda x,y:  x.dot(y.T)/((norm(x)*norm(y))+1e-4)\n",
    "    num_ts,num_tr = len(qd),len(data)\n",
    "\n",
    "    nbrs = np.zeros((num_ts,k),dtype=np.int32)\n",
    "    nvals = np.zeros((num_ts,k),dtype=np.double)\n",
    "\n",
    "    qpre_data = [shingleText(row) for row in preProcessData(qd)]\n",
    "    queries = []\n",
    "    for sdoc in qpre_data:\n",
    "        tli = dict()\n",
    "        for swrd in sdoc:\n",
    "            if wrds.get(swrd,0):\n",
    "                tli[wrds[swrd]-1] = tli.get(wrds[swrd]-1,0) + 1\n",
    "        queries.append(tli)\n",
    "    for i in range(num_ts):\n",
    "        #simd = [sim_func(qd[i],data[j]) for j in range(num_tr)]\n",
    "        arr1 = np.asarray([0.0]*len(wrds))\n",
    "        qD = queries[i]\n",
    "        for key in qD:\n",
    "            arr1[key] += float(qD[key])\n",
    "        simd = []\n",
    "        for j in range(num_tr):\n",
    "            arr2 = np.asarray([0.0]*len(wrds))\n",
    "            np.put(arr2,list(data[j].keys()),list(data[j].values()))\n",
    "            simd.append(sim_func(arr1,arr2))\n",
    "        prob = np.argsort(simd)\n",
    "        nbrs[i,:] = prob[:k]\n",
    "        nvals[i,:] = [simd[k] for j in prob[:k]]\n",
    "    return nbrs,nvals\n",
    "\n",
    "def recall(predicted,true_nbr):\n",
    "    acc = 0.0\n",
    "    n,k = true_nbr.shape\n",
    "    for i in range(n):\n",
    "        x,y = predicted[i,:],true_nbr[i,:]\n",
    "        acc += np.interesect1d(x,y).shape[0]/float(k)\n",
    "    return acc/float(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cenhlEOIrvh"
   },
   "outputs": [],
   "source": [
    "def searcher(query_data):\n",
    "    t0 = time.time()\n",
    "    q_d = l1.encodeQueryData(query_data)\n",
    "    \n",
    "    lnbr,lnval = l1.findSimDocs(q_d)\n",
    "    t1 = time.time()\n",
    "    t2 = time.time()\n",
    "    nnbr,nnval = naiveSimDocs(fdata,query_data,wrds)\n",
    "    t3 = time.time()\n",
    "    return lnbr,lnval,nnbr,nnval,t1-t0,t3-t2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fB9ZgRS1N-80"
   },
   "outputs": [],
   "source": [
    "queries = [\"\"\"FAO Fisheries Circular No. 1012\"\"\",\"\"\"letters to nature\n",
    "typically\"\"\",\"\"\"Molecular Systems Biology 4; Article number 159; doi:10\"\"\",\"\"\"Alignment Uncertainty and Genomic Analysis Karen M. Wong, et al. Science 319, 473 (2008\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xbatlWLwfS1",
    "outputId": "1c9ca589-7544-41b4-9565-518d87c6a1b9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "time_takenLSH,time_takenN = [],[]\n",
    "for i in range(len(queries)):\n",
    "    out = searcher(queries[:i+1])\n",
    "    time_takenLSH.append(out[5])\n",
    "    time_takenN.append(out[-1])\n",
    "\n",
    "plt.plot(time_takenLSH)\n",
    "plt.plot(time_takenN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
